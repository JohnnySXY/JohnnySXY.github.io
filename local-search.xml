<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>日志处理-Grok正则捕获</title>
    <link href="/2023/04/21/%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86-Grok%E6%AD%A3%E5%88%99%E6%8D%95%E8%8E%B7/"/>
    <url>/2023/04/21/%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86-Grok%E6%AD%A3%E5%88%99%E6%8D%95%E8%8E%B7/</url>
    
    <content type="html"><![CDATA[<p>一般系统或服务生成的日志都是一大长串。每个字段之间用空格隔开。logstash在获取日志是整个一串获取，如果把日志中每个字段代表的意思分割开来在传给elasticsearch。这样呈现出来的数据更加清晰，而且也能让kibana更方便的绘制图形。</p><p>Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。</p><h2 id="Grok-正则捕获"><a href="#Grok-正则捕获" class="headerlink" title="Grok 正则捕获"></a><strong>Grok 正则捕获</strong></h2><p>Grok 支持把预定义的 grok 表达式 写入到文件中，官方提供的预定义 grok 表达式见：<a href="https://github.com/logstash/logstash/tree/v1.4.2/patterns%E3%80%82">https://github.com/logstash/logstash/tree/v1.4.2/patterns。</a></p><p><code>%&#123;syntax:semantic&#125;</code></p><p>syntax代表的是正则表达式替代字段，semantic是代表这个表达式对应的字段名，你可以自由命名。这个命名尽量能简单易懂的表达出这个字段代表的意思。</p><p>logstash安装时就带有已经写好的正则表达式。路径如下：</p><p><code>/usr/local/logstash-2.3.4/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns</code></p><p>或者直接访问logstash-plugins&#x2F;logstash-patterns-core · GitHub</p><p>上面IPORHOST，USER等都是在里面已经定义好的！当然还有其他的，基本能满足我们的需求。</p><h2 id="grok-patterns"><a href="#grok-patterns" class="headerlink" title="grok-patterns"></a><strong>grok-patterns</strong></h2><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "physical id  USERNAME [a-zA-Z0-9._-]+  USER %&#123;USERNAME&#125;  EMAILLOCALPART [a-zA-Z0-9!#$%&'*+\-/=?^_`&#123;|&#125;~]&#123;1,64&#125;(?:\.[a-zA-Z0-9!#$%&'*+\-/=?^_`&#123;|&#125;~]&#123;1,62&#125;)&#123;0,63&#125;  EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;  INT (?:[+-]?(?:[0-9]+))  BASE10NUM (?<![0-9.+-])(?>[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))  NUMBER (?:%&#123;BASE10NUM&#125;)  BASE16NUM (?<![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))  BASE16FLOAT \b(?<![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\b  <p>  POSINT \b(?:[1-9][0-9]<em>)\b<br>  NONNEGINT \b(?:[0-9]+)\b<br>  WORD \b\w+\b<br>  NOTSPACE \S+<br>  SPACE \s</em><br>  DATA .<em>?<br>  GREEDYDATA .</em><br>  QUOTEDSTRING (?&gt;(?&lt;!\)(?&gt;”(?&gt;\.|[^\“]+)+”|””|(?&gt;’(?&gt;\.|[^\‘]+)+’)|’’|(?&gt;<code>(?&gt;\\.|[^\\</code>]+)+&#96;)|&#96;&#96;))<br>  UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12}<p></p><h1 id="URN-allowing-use-of-RFC-2141-section-2-3-reserved-characters"><a href="#URN-allowing-use-of-RFC-2141-section-2-3-reserved-characters" class="headerlink" title="URN, allowing use of RFC 2141 section 2.3 reserved characters"></a>URN, allowing use of RFC 2141 section 2.3 reserved characters</h1><p>  URN urn:[0-9A-Za-z][0-9A-Za-z-]{0,31}:(?:%[0-9a-fA-F]{2}|[0-9A-Za-z()+,.:&#x3D;@;$_!*’&#x2F;?#-])+  </p><h1 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h1><p>  MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})<br>  CISCOMAC (?:(?:[A-Fa-f0-9]{4}.){2}[A-Fa-f0-9]{4})<br>  WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})<br>  COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})<br>  IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?<br>  IPV4 (?&lt;![0-9])(?:(?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])<a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a><a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a><a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a>)(?![0-9])<br>  IP (?:%{IPV6}|%{IPV4})<br>  HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(.?|\b)<br>  IPORHOST (?:%{IP}|%{HOSTNAME})<br>  HOSTPORT %{IPORHOST}:%{POSINT}  </p><h1 id="paths-only-absolute-paths-are-matched"><a href="#paths-only-absolute-paths-are-matched" class="headerlink" title="paths (only absolute paths are matched)"></a>paths (only absolute paths are matched)</h1><p>  PATH (?:%{UNIXPATH}|%{WINPATH})<br>  UNIXPATH (&#x2F;[[[:alnum:]]_%!$@:.,+~-]<em>)+<br>  TTY (?:&#x2F;dev&#x2F;(pts|tty([pq])?)(\w+)?&#x2F;?(?:[0-9]+))<br>  WINPATH (?&gt;[A-Za-z]+:|\)(?:\[^\?</em>]*)+<br>  URIPROTO <a href="%5BA-Za-z0-9+-.%5D+">A-Za-z</a>+<br>  URIHOST %{IPORHOST}(?::%{POSINT})?</p><h1 id="uripath-comes-loosely-from-RFC1738-but-mostly-from-what-Firefox-doesn’t-turn-into-XX"><a href="#uripath-comes-loosely-from-RFC1738-but-mostly-from-what-Firefox-doesn’t-turn-into-XX" class="headerlink" title="uripath comes loosely from RFC1738, but mostly from what Firefox doesn’t turn into %XX"></a>uripath comes loosely from RFC1738, but mostly from what Firefox doesn’t turn into %XX</h1><p>  URIPATH (?:&#x2F;[A-Za-z0-9$.+!<em>‘(){},~:;&#x3D;@#%&amp;_-]</em>)+<br>  URIQUERY [A-Za-z0-9$.+!<em>‘|(){},~@#%&amp;&#x2F;&#x3D;:;_?-[]&lt;&gt;]</em></p><h1 id="deprecated-kept-due-compatibility"><a href="#deprecated-kept-due-compatibility" class="headerlink" title="deprecated (kept due compatibility):"></a>deprecated (kept due compatibility):</h1><p>  URIPARAM ?%{URIQUERY}<br>  URIPATHPARAM %{URIPATH}(?:?%{URIQUERY})?<br>  URI %{URIPROTO}:&#x2F;&#x2F;(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATH}(?:?%{URIQUERY})?)?  </p><h1 id="Months-January-Feb-3-03-12-December"><a href="#Months-January-Feb-3-03-12-December" class="headerlink" title="Months: January, Feb, 3, 03, 12, December"></a>Months: January, Feb, 3, 03, 12, December</h1><p>  MONTH \b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|<a href="?:a%7C%C3%A4">Mm</a>?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y|i)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|<a href="?:c%7Ck">Oo</a>?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\b<br>  MONTHNUM (?:0?[1-9]|1[0-2])<br>  MONTHNUM2 (?:0[1-9]|1[0-2])<br>  MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])  </p><h1 id="Days-Monday-Tue-Thu-etc…"><a href="#Days-Monday-Tue-Thu-etc…" class="headerlink" title="Days: Monday, Tue, Thu, etc…"></a>Days: Monday, Tue, Thu, etc…</h1><p>  DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)  </p><h1 id="Years"><a href="#Years" class="headerlink" title="Years?"></a>Years?</h1><p>  YEAR (?&gt;\d\d){1,2}<br>  HOUR (?:2[0123]|[01]?[0-9])<br>  MINUTE (?:[0-5][0-9])</p><h1 id="‘60’-is-a-leap-second-in-most-time-standards-and-thus-is-valid"><a href="#‘60’-is-a-leap-second-in-most-time-standards-and-thus-is-valid" class="headerlink" title="‘60’ is a leap second in most time standards and thus is valid."></a>‘60’ is a leap second in most time standards and thus is valid.</h1><p>  SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)<br>  TIME (?!&lt;[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9])</p><h1 id="datestamp-is-YYYY-x2F-MM-x2F-DD-HH-MM-SS-UUUU-or-something-like-it"><a href="#datestamp-is-YYYY-x2F-MM-x2F-DD-HH-MM-SS-UUUU-or-something-like-it" class="headerlink" title="datestamp is YYYY&#x2F;MM&#x2F;DD-HH:MM:SS.UUUU (or something like it)"></a>datestamp is YYYY&#x2F;MM&#x2F;DD-HH:MM:SS.UUUU (or something like it)</h1><p>  DATE_US %{MONTHNUM}[&#x2F;-]%{MONTHDAY}[&#x2F;-]%{YEAR}<br>  DATE_EU %{MONTHDAY}[.&#x2F;-]%{MONTHNUM}[.&#x2F;-]%{YEAR}<br>  ISO8601_TIMEZONE (?:Z|[+-]%{HOUR}(?::?%{MINUTE}))<br>  ISO8601_SECOND %{SECOND}<br>  TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?<br>  DATE %{DATE_US}|%{DATE_EU}<br>  DATESTAMP %{DATE}[- ]%{TIME}<br>  TZ (?:[APMCE][SD]T|UTC)<br>  DATESTAMP_RFC822 %{DAY} %{MONTH} %{MONTHDAY} %{YEAR} %{TIME} %{TZ}<br>  DATESTAMP_RFC2822 %{DAY}, %{MONTHDAY} %{MONTH} %{YEAR} %{TIME} %{ISO8601_TIMEZONE}<br>  DATESTAMP_OTHER %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{TZ} %{YEAR}<br>  DATESTAMP_EVENTLOG %{YEAR}%{MONTHNUM2}%{MONTHDAY}%{HOUR}%{MINUTE}%{SECOND}  </p><h1 id="Syslog-Dates-Month-Day-HH-MM-SS"><a href="#Syslog-Dates-Month-Day-HH-MM-SS" class="headerlink" title="Syslog Dates: Month Day HH:MM:SS"></a>Syslog Dates: Month Day HH:MM:SS</h1><p>  SYSLOGTIMESTAMP %{MONTH} +%{MONTHDAY} %{TIME}<br>  PROG [\x21-\x5a\x5c\x5e-\x7e]+<br>  SYSLOGPROG %{PROG:[process][name]}(?:[%{POSINT:[process][pid]:int}])?<br>  SYSLOGHOST %{IPORHOST}<br>  SYSLOGFACILITY &lt;%{NONNEGINT:[log][syslog][facility][code]:int}.%{NONNEGINT:[log][syslog][priority]:int}&gt;<br>  HTTPDATE %{MONTHDAY}&#x2F;%{MONTH}&#x2F;%{YEAR}:%{TIME} %{INT}  </p><h1 id="Shortcuts"><a href="#Shortcuts" class="headerlink" title="Shortcuts"></a>Shortcuts</h1><p>  QS %{QUOTEDSTRING}  </p><h1 id="Log-formats"><a href="#Log-formats" class="headerlink" title="Log formats"></a>Log formats</h1><p>  SYSLOGBASE %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:[host][hostname]} %{SYSLOGPROG}:  </p><h1 id="Log-Levels"><a href="#Log-Levels" class="headerlink" title="Log Levels"></a>Log Levels</h1><p>  LOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo?(?:rmation)?|INFO?(?:RMATION)?|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)<br>  </p></code></pre><p></p></figure><h2 id="案例实践"><a href="#案例实践" class="headerlink" title="案例实践"></a><strong>案例实践</strong></h2><p><strong>例1</strong>：将下面的日志文件格式拆分为5段</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  2016-09-19T18:19:00 [8.8.8.8:prd] DEBUG this is an example log message  </code></pre></figure><ul><li>时间</li><li>IP地址</li><li>环境</li><li>等级</li><li>信息</li></ul><p>使用Grok 默认提供的正则匹配后</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;TIMESTAMP_ISO8601:timestamp&#125; \[%&#123;IPV4:ip&#125;;%&#123;WORD:environment&#125;\] %&#123;LOGLEVEL:log_level&#125; %&#123;GREEDYDATA:message&#125;    <p>  这样就会生成结构化结果：<br>  &#123;<br>    “timestamp”: “2016-09-19T18:19:00”,<br>    “ip”: “8.8.8.8”,<br>    “environment”: “prd”,<br>    “log_level”: “DEBUG”,<br>    “message”: “this is an example log message”<br>  &#125;<br>  </p></code></pre><p></p></figure>`TIMESTAMP_ISO8601`用来匹配时间<p><code>IPV4</code>匹配IPV4 IP地址</p><p><code>WORD</code>匹配环境</p><p><code>LOGLEVEL</code>匹配了日志等级</p><p><code>GREEDYDATA</code>匹配后面的所有内容</p><p>例2：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] "GET /blog/geekery/xvfb-firefox.html HTTP/1.1" 200 10975 "-" "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)"  </code></pre></figure><p>转换后：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;IPORHOST:clientip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "%&#123;WORD:verb&#125; %&#123;DATA:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;" %&#123;NUMBER:response:int&#125; (?:-|%&#123;NUMBER:bytes:int&#125;) %&#123;QS:referrer&#125; %&#123;QS:agent&#125;  </code></pre></figure><p>例3：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] "GET /blog/geekery/xvfb-firefox.html HTTP/1.1" 200 10975 "-" "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)"  </code></pre></figure><p>转换后：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;IPORHOST:clientip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "%&#123;WORD:verb&#125; %&#123;DATA:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;" %&#123;NUMBER:response:int&#125; (?:-|%&#123;NUMBER:bytes:int&#125;) %&#123;QS:referrer&#125; %&#123;QS:agent&#125;  </code></pre></figure><p>例4：假设我们有三个使用“common_header：payload”格式的应用程序</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  Application 1: '8.8.8.8 process-name[666]: a b 1 2 a lot of text at the end'<p>  Application 2: ‘8.8.8.8 process-name[667]: a 1 2 3 a lot of text near the end;4’</p><p>  Application 3: ‘8.8.8.8 process-name[421]: a completely different format | 1111’<br>  </p></code></pre><p></p></figure><p>转换后：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  grok &#123;  "match" => &#123; "message => [    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;WORD:word_1&#125; %&#123;WORD:word_2&#125; %&#123;NUMBER:number_1&#125; %&#123;NUMBER:number_2&#125; %&#123;DATA:data&#125;',    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;WORD:word_1&#125; %&#123;NUMBER:number_1&#125; %&#123;NUMBER:number_2&#125; %&#123;NUMBER:number_3&#125; %&#123;DATA:data&#125;;%&#123;NUMBER:number_4&#125;',    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;DATA:data&#125; | %&#123;NUMBER:number&#125;'    ] &#125;&#125;  </code></pre></figure><p>下面针对Apache日志来分割处理</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  192.168.10.97 - - [19/Jul/2016:16:28:52 +0800] "GET / HTTP/1.1" 200 23 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36"  </code></pre></figure><p>日志中每个字段之间空格隔开，分别对应message中的字段。</p><p>如：%{IPORHOST:addre} –&gt; 192.168.10.97</p><p>但问题是IPORHOST又不是正则表达式，怎么能匹配IP地址呢？</p><p>因为IPPRHOST是grok表达式，它代表的正则表达式如下：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  IPV6 ((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)?  IPV4 (?<![0-9])(?:(?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5]))(?![0-9])  IP (?:%&#123;IPV6&#125;|%&#123;IPV4&#125;)  HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b)  IPORHOST (?:%&#123;IP&#125;|%&#123;HOSTNAME&#125;)  </code></code></pre></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  IPORHOST代表的是ipv4或者ipv6或者HOSTNAME所匹配的grok表达式。<p>  上面的IPORHOST有点复杂，我们来看看简单点的，如USER</p><p>  USERNAME [a-zA-Z0-9._-]+     </p><p>  #USERNAME是匹配由字母，数字，“.”, “_”, “-“组成的任意字符</p><p>  USER %&#123;USERNAME&#125;</p><p>  #USER代表USERNAME的正则表达式</p><p>  第一行，用普通的正则表达式来定义一个 grok 表达式；</p><p>  第二行，通过打印赋值格式，用前面定义好的 grok 表达式来定义另一个 grok 表达式。<br>  </p></code></pre><p></p></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  filter &#123;    if [type] == "apache" &#123;      grok &#123;        match => ["message" => "%&#123;IPORHOST:addre&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \"%&#123;WORD:http_method&#125; %&#123;NOTSPACE:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\" %&#123;NUMBER:status&#125; (?:%&#123;NUMBER:bytes&#125;|-) \"(?:%&#123;URI:http_referer&#125;|-)\" \"%&#123;GREEDYDATA:User_Agent&#125;\""]        remove_field => ["message"]      &#125;      date &#123;        match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]      &#125;    &#125;  &#125;  </code></pre></figure>  filter {    if [type] == "apache" {      grok {        match => ["message" => "%{IPORHOST:addre} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:http_method} %{NOTSPACE:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:status} (?:%{NUMBER:bytes}|-) \"(?:%{URI:http_referer}|-)\" \"%{GREEDYDATA:User_Agent}\""]        remove_field => ["message"]      }      date {        match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]      }    }  }<p>Httpd</p><p>HTTPDUSER %{EMAILADDRESS}|%{USER}<br>HTTPDERROR_DATE %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}</p><h1 id="Log-formats-1"><a href="#Log-formats-1" class="headerlink" title="Log formats"></a>Log formats</h1><p>HTTPD_COMMONLOG %{IPORHOST:clientip} %{HTTPDUSER:ident} %{HTTPDUSER:auth} [%{HTTPDATE:timestamp}] “(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP&#x2F;%{NUMBER:httpversion})?|%{DATA:rawrequest})” %{NUMBER:response} (?:%{NUMBER:bytes}|-)<br>HTTPD_COMBINEDLOG %{HTTPD_COMMONLOG} %{QS:referrer} %{QS:agent}</p><h1 id="Error-logs"><a href="#Error-logs" class="headerlink" title="Error logs"></a>Error logs</h1><p>HTTPD20_ERRORLOG [%{HTTPDERROR_DATE:timestamp}] [%{LOGLEVEL:loglevel}] (?:[client %{IPORHOST:clientip}] ){0,1}%{GREEDYDATA:message}<br>HTTPD24_ERRORLOG [%{HTTPDERROR_DATE:timestamp}] [%{WORD:module}:%{LOGLEVEL:loglevel}] [pid %{POSINT:pid}(:tid %{NUMBER:tid})?]( (%{POSINT:proxy_errorcode})%{DATA:proxy_message}:)?( [client %{IPORHOST:clientip}:%{POSINT:clientport}])?( %{DATA:errorcode}:)? %{GREEDYDATA:message}<br>HTTPD_ERRORLOG %{HTTPD20_ERRORLOG}|%{HTTPD24_ERRORLOG}</p><h1 id="Deprecated"><a href="#Deprecated" class="headerlink" title="Deprecated"></a>Deprecated</h1><p>COMMONAPACHELOG %{HTTPD_COMMONLOG}<br>COMBINEDAPACHELOG %{HTTPD_COMBINEDLOG}</p><p>java<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>JAVACLASS (?:[a-zA-Z$_][a-zA-Z$<em>0-9]<em>.)</em>[a-zA-Z$</em>][a-zA-Z$_0-9]*</p><p>#Space is an allowed character to match special cases like ‘Native Method’ or ‘Unknown Source’<br>JAVAFILE (?:[A-Za-z0-9_. -]+)</p><p>#Allow special <init>, <clinit> methods<br>JAVAMETHOD (?:(&lt;(?:cl)?init&gt;)|[a-zA-Z$_][a-zA-Z$_0-9]*)</clinit></init></p><p>#Line number is optional in special cases ‘Native method’ or ‘Unknown source’<br>JAVASTACKTRACEPART %{SPACE}at %{JAVACLASS:class}.%{JAVAMETHOD:method}(%{JAVAFILE:file}(?::%{NUMBER:line})?)</p><h1 id="Java-Logs"><a href="#Java-Logs" class="headerlink" title="Java Logs"></a>Java Logs</h1><p>JAVATHREAD (?:[A-Z]{2}-Processor[\d]+)<br>JAVACLASS (?:[a-zA-Z0-9-]+.)+[A-Za-z0-9$]+<br>JAVAFILE (?:[A-Za-z0-9_.-]+)<br>JAVALOGMESSAGE (.*)</p><h1 id="MMM-dd-yyyy-HH-mm-ss-eg-Jan-9-2014-7-13-13-AM"><a href="#MMM-dd-yyyy-HH-mm-ss-eg-Jan-9-2014-7-13-13-AM" class="headerlink" title="MMM dd, yyyy HH:mm:ss eg: Jan 9, 2014 7:13:13 AM"></a>MMM dd, yyyy HH:mm:ss eg: Jan 9, 2014 7:13:13 AM</h1><p>CATALINA_DATESTAMP %{MONTH} %{MONTHDAY}, 20%{YEAR} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) (?:AM|PM)</p><h1 id="yyyy-MM-dd-HH-mm-ss-SSS-ZZZ-eg-2014-01-09-17-32-25-527-0800"><a href="#yyyy-MM-dd-HH-mm-ss-SSS-ZZZ-eg-2014-01-09-17-32-25-527-0800" class="headerlink" title="yyyy-MM-dd HH:mm:ss,SSS ZZZ eg: 2014-01-09 17:32:25,527 -0800"></a>yyyy-MM-dd HH:mm:ss,SSS ZZZ eg: 2014-01-09 17:32:25,527 -0800</h1><p>TOMCAT_DATESTAMP 20%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{HOUR}:?%{MINUTE}(?::?%{SECOND}) %{ISO8601_TIMEZONE}<br>CATALINALOG %{CATALINA_DATESTAMP:timestamp} %{JAVACLASS:class} %{JAVALOGMESSAGE:logmessage}</p><h1 id="2014-01-09-20-03-28-269-0800-ERROR-com-example-service-ExampleService-something-compeletely-unexpected-happened…"><a href="#2014-01-09-20-03-28-269-0800-ERROR-com-example-service-ExampleService-something-compeletely-unexpected-happened…" class="headerlink" title="2014-01-09 20:03:28,269 -0800 | ERROR | com.example.service.ExampleService - something compeletely unexpected happened…"></a>2014-01-09 20:03:28,269 -0800 | ERROR | com.example.service.ExampleService - something compeletely unexpected happened…</h1><p>TOMCATLOG %{TOMCAT_DATESTAMP:timestamp} | %{LOGLEVEL:level} | %{JAVACLASS:class} - %{JAVALOGMESSAGE:logmessage}</p><p>Grok Debugger<br>当我们拿到一段日志，按照上面的grok表达式一个个去匹配时，我们如何确定我们匹配的是否正确呢？</p><p><a href="http://grokdebug.herokuapp.com/">http://grokdebug.herokuapp.com/</a> 这个地址可以满足我们的测试需求。就拿上面apache的日志测试。</p><p>grok-debugger<br>grok-debugger</p><p>点击后就出现如下数据，你写的每个grok表达式都获取到值了。为了测试准确，可以多测试几条日志。</p><p>效果：</p><p>grok-pz<br>grok-pz</p><p>kibana字段展示：</p><p>grok-kibana<br>grok-kibana</p><p>配置文件：</p><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27</p><h1 id="—————input-输入模块———————–"><a href="#—————input-输入模块———————–" class="headerlink" title="—————input 输入模块———————–"></a>—————input 输入模块———————–</h1><p>input {<br>beats {<br>port &#x3D;&gt; 5044<br>}<br>}</p><h1 id="—————filter-过滤模块———————–"><a href="#—————filter-过滤模块———————–" class="headerlink" title="—————filter 过滤模块———————–"></a>—————filter 过滤模块———————–</h1><p>filter {<br>    grok {<br>        match &#x3D;&gt; {<br>            “message” &#x3D;&gt; “%{TIMESTAMP_ISO8601:times} %{HOSTNAME:hosts} %{USERNAME:logtype}: message repeated %{INT:repetition_times} times: [ 日志类型:(?<Operation_type>(?&lt;&#x3D;)(.{4})), (?<Operation_typ1e>(?&lt;&#x3D;)(.{2})):%{USER:user}(%{HOSTNAME:connection_method})(%{HOSTNAME:connection_method}), IP地址:%{IPV4:connection_ip}, 操作对象:%{GREEDYDATA:Action_log}, 操作类型:(?<behaviour_t>(?&lt;&#x3D;)(.{4})), 描述:(?<Behavior_performance>(?&lt;&#x3D;)(.{4}))]“<br>        }<br>    }<br>}</Behavior_performance></behaviour_t></Operation_typ1e></Operation_type></p><h1 id="—————output-输出模块———————–"><a href="#—————output-输出模块———————–" class="headerlink" title="—————output 输出模块———————–"></a>—————output 输出模块———————–</h1><p>output {<br>elasticsearch {<br>hosts &#x3D;&gt; [“<a href="http://localhost:9200" ]">http://localhost:9200&quot;]</a><br>index &#x3D;&gt; “sangfor-af-%{+YYYY.MM.dd}”<br>#user &#x3D;&gt; “elastic”<br>#password &#x3D;&gt; “changeme”<br>}<br>}</p><p>自定义grok表达式<br>grok主要有两部分：自定义正则表达式和系统预定义的模式表达式。</p><p>如果你感觉logstash自带的grok表达式不能满足需要，你也可以自己定义</p><p>如：</p><p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>filter {<br>  if [type] &#x3D;&#x3D; “apache” {<br>    grok {<br>      patterns_dir &#x3D;&gt; “&#x2F;usr&#x2F;local&#x2F;logstash-2.3.4&#x2F;ownpatterns&#x2F;patterns”<br>      match &#x3D;&gt; {<br>                “message” &#x3D;&gt; “%{APACHE_LOG}”<br>                }<br>      remove_field &#x3D;&gt; [“message”]<br>    }<br>    date {<br>      match &#x3D;&gt; [ “timestamp”, “dd&#x2F;MMM&#x2F;YYYY:HH:mm:ss Z” ]<br>    }<br>  }<br>}</p><p>#patterns_dir为自定义的grok表达式的路径。<br>#自定义的patterns中按照logstash自带的格式书写。</p><p>1<br>2<br>3<br>APACHE_LOG %{IPORHOST:addre} %{USER:ident} %{USER:auth} [%{HTTPDATE:timestamp}] &quot;%{WORD:http_method} %{NOTSPACE:request} HTTP&#x2F;%{NUMBER:httpversion}&quot; %{NUMBER:status} (?:%{NUMBER:bytes}|-) &quot;(?:%{URI:http_referer}|-)&quot; &quot;%{GREEDYDATA:User_Agent}&quot;</p><p>#我只是把apache日志匹配的grok表达式写入自定义文件中，简化conf文件。单个字段的正则表达式匹配你可以自己书写测试。</p><p>常用正则<br>1<br>2<br>3<br>4<br>5<br>6<br>7<br>(?<temMsg>(.<em>)(?&#x3D;Report)&#x2F;?) 获取Report之前的字符<br>(?<temMsg>(?&#x3D;Report)(.</temMsg></em>)&#x2F;?) 获取Report之后的字符<br>(?<temMsg>(?&lt;&#x3D;report).<em>?(?&#x3D;msg)) 截取report和msg之间的值 不包含report和msg本身<br>(?<temMsg>(report).</temMsg></em>?(?&#x3D;msg)) 截取包含report但不包含msg<br>(?<temMsg>(?&lt;&#x3D;report).<em>?(msg)) 截取不包含report但包含msg<br>(?<temMsg>(report).</temMsg></em>?(msg|request)) 输出以report开头,以msg或者以request结尾的所有包含头尾信息<br>(?<temMsg>(report).*?(?&#x3D;(msg|request))) 输出以report开头,以msg或者以request结尾的不包含头尾信息</temMsg></temMsg></temMsg></temMsg></p><p>grok截取字符中指定长度的内容<br>要求利用grok截取日志消息中某一指定长度的内容。</p><p>Logstatsh需要两个必需参数input、output，以及一个可选参数filter。input用于输入数据的设置，output用于输出数据的设置。filter是实现数据过滤的设置。grok是在filter里面实现数据截取。</p><p>项目有一串协议消息如 7e8900000c040116432693324af0010180010005e98e0706000a7e，要求利用grok截取7e后面的四个字符，利用grok正则表达式即可实现。<br>实现代码如下：</p><p>1<br>2<br>3<br>4<br>5<br>filter{<br>grok{ match &#x3D;&gt; {<br>“message” &#x3D;&gt; “(?<mid>(?&lt;&#x3D;7e)(.{4}))” }<br> }<br>}<br>代码解释：</mid></p><p>message：即输入的数据信息。</p><p>mid：即输出结果的名称</p><p>(?&lt;&#x3D;7e)：即表示获取7e后面的字符，但不包括7e</p><p>(.{4})：即表示获取的字符长度为4个</p><p>引用文章：</p><p>Grok 正则捕获 | Logstash 最佳实践 (yonyoucloud.com)</p><p>logstash-patterns-core (github.com)</p><p>Logstash 常用正则（grok-patterns）qianghong000_51CTO博客</p><p><a href="https://blog.51cto.com/irow10/1828077">https://blog.51cto.com/irow10/1828077</a></p><p>Logstash Grok详解_叱咤少帅的博客-CSDN博客</p><p>轻松掌握Logstash的grok匹配_全菜工程师小辉的博客-CSDN博客</p><p>logstash截取指定字符和grok的使用_cai750415222的博客-CSDN博客</p>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日志</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AWS数据传输费用怎么算？</title>
    <link href="/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/"/>
    <url>/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="AWS的数据传输类型大致有如下三类："><a href="#AWS的数据传输类型大致有如下三类：" class="headerlink" title="AWS的数据传输类型大致有如下三类："></a><strong>AWS的数据传输类型大致有如下三类</strong>：</h2><ul><li>与Internet之间的数据传输</li><li>AWS内部跨区域的数据传输</li><li>AWS内部同一区域的数据传输<br>本文将以ap-southeast-2区域中的EC2和S3为例。</li></ul><h2 id="与Internet之间的数据传输费用计算"><a href="#与Internet之间的数据传输费用计算" class="headerlink" title="与Internet之间的数据传输费用计算"></a><strong>与Internet之间的数据传输费用计算</strong></h2><p>所有从Internet到AWS的流量是免费的，所有从AWS到Internet的流量是收费的。即对AWS服务而言，上行收费，下行免费。</p><p>针对上行流量，AWS根据不同的使用量采用不同的费率，下表中展示的是ap-southeast-2区域从AWS到Internet的数据传输费率。</p><table><thead><tr><th>Rate tiers</th><th>Pricing</th></tr></thead><tbody><tr><td>Up to 1 GB &#x2F; Month</td><td>$0.00 per GB</td></tr><tr><td>Next 9.999 TB</td><td>$0.114 per GB</td></tr><tr><td>Next 40 TB &#x2F; Month</td><td>$0.098 per GB</td></tr><tr><td>Next 100 TB &#x2F; Month</td><td>$0.094 per GB</td></tr><tr><td>Greater than 150 TB &#x2F; Month</td><td>$0.092 per GB</td></tr></tbody></table><p>那么问题来了，在这一个月中S3和EC2均产生了1GB到Internet的上行流量，AWS应该收我多少钱？$0? 不是的，会产生 $0.114 费用。</p><h2 id="为啥？"><a href="#为啥？" class="headerlink" title="为啥？"></a><strong>为啥？</strong></h2><p>AWS会根据从AWS服务传输到Internet的数据总量计算数据传输费率。具体而言，AWS会将从Amazon EC2, Amazon S3, Amazon Glacier, Amazon RDS, Amazon Redshift, Amazon SES, Amazon SimpleDB, Amazon SQS, Amazon SNS, Amazon DynamoDB, AWS Storage Gateway, 和 Amazon CloudWatch Logs到Internet的流量进行合并计算数据传输费率。</p><p>比如，我们只使用了EC2和S3服务，在本月我们已经使用了10TB，那么接下来EC2或者S3到Internet的费用到会按照$0.098&#x2F;GB收费，知道使用到下一个费率标准。</p><p>简单说，下行免费，上行收费，费率算总量。</p><h2 id="跨区域的数据传输费用计算"><a href="#跨区域的数据传输费用计算" class="headerlink" title="跨区域的数据传输费用计算"></a><strong>跨区域的数据传输费用计算</strong></h2><p>不同区域对跨区域数据传输的费率是不一样的。对于上行的数据传输会按照费率收取费用，对于下行的数据传输不收费。</p><p>比如现在有2台EC2实例A和B，A在悉尼(ap-southeast-2)，B在新加坡(ap-southeast-1)。这两台实例之间如何收取数据传输费用？</p><p>已知从悉尼ap-southeast-2到其他区域的数据传输费用为 $0.14&#x2F;GB，从新加坡ap-southeast-1到其他区域的数据传输费用为 $0.09&#x2F;GB</p><p>则从A给B传输1GB的数据，A需要付出数据传输费用 $0.14，B不需要付费。从B给A传输1GB的数据，A不需要付费，B需要付费 $0.09。</p><p>下行免费，上行收费，费率分区域。</p><h2 id="到CloudFront的数据传输费用计算"><a href="#到CloudFront的数据传输费用计算" class="headerlink" title="到CloudFront的数据传输费用计算"></a><strong>到CloudFront的数据传输费用计算</strong></h2><p>无论EC2还是S3到CloudFront的数据传输都是免费的。</p><h2 id="同一区域内的数据传输费用计算"><a href="#同一区域内的数据传输费用计算" class="headerlink" title="同一区域内的数据传输费用计算"></a><strong>同一区域内的数据传输费用计算</strong></h2><h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a><strong>S3</strong></h2><p>S3 bucket之间在同一区域进行数据传输不收费。</p><p>S3和其他AWS服务在同一区域进行数据传输不收费。比如EC2和S3之间传输数据是免费的。</p><h2 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a><strong>EC2</strong></h2><ul><li><p>Amazon EC2，Amazon RDS，Amazon Redshift，Amazon DynamoDB Accelerator（DAX），Amazon ElastiCach 和 Elastic Network Interfaces进行跨可用区或使用VPC对等连接传输数据，上下行都需要收费，$0.01&#x2F;GB<br>比如在可用区A中有1台EC2 EC2-A，在可用区B中有1台EC EC2-B。当EC2-A向EC2-B传输1G数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p></li><li><p>同一个区域内，使用公网IPv4或者弹性IPv4地址传输数据，上下行都需要收费，$0.01&#x2F;GB。<br>比如在可用区A中有两台EC2 EC2-A和EC2-B，它们之间使用公网IP传输数据是需要收费的，假如EC2-A向EC2-B发送1GB的数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p></li></ul><p>Q: 跨可用区使用Public IP传输数据如何收费？<br>跨区域使用Public IP或者EIP传输数据只会收一次费用。<br>比如在可用区A中有1台EC2 EC2-A，在可用区B中有1台EC EC2-B。当EC2-A通过EIP向EC2-B传输1G数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p><ul><li><p>同一个区域内，使用IPv6跨VPC传输数据，上下行都需要收费，$0.01&#x2F;GB。</p></li><li><p>同一个可用区内Amazon EC2, Amazon RDS, Amazon Redshift, Amazon ElastiCache instances 和 Elastic Network Interfaces 之间传输数据免费。如果使用VPC对等连接，则需要按照VPC对等连接的费率收费。</p></li></ul><p>比如在可用区A中有两台EC2 EC2-A和EC2-B，它们之间使用私有IP传输数据是免费的。</p><ul><li><p>在同一区域中内 Amazon S3、Amazon Glacier、Amazon DynamoDB、Amazon SES、Amazon SQS、Amazon Kinesis、Amazon ECR、Amazon SNS、Amazon SimpleDB 和 Amazon EC2 实例之间传输数据是免费的。通过PrivateLink终端节点访问的AWS服务将产生标准PrivateLink费用。</p></li><li><p>使用私有 IP 地址从 Amazon Classic Elastic Load Balancer 和 Amazon Application Elastic Load Balancer与EC2 实例之间传输数据是免费的。</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p><strong>EC2</strong><br><img src="https://github.com/JohnnySXY/JohnnySXY.github.io/blob/master/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/ec2.png?raw=true"></p><p><strong>S3</strong><br><img src="https://github.com/JohnnySXY/JohnnySXY.github.io/blob/master/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/s3.png?raw=true"></p>]]></content>
    
    
    <categories>
      
      <category>CLOUD</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AWS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于如何在hexo博客上发布和删除博文</title>
    <link href="/2023/04/20/Hexo-Release-OR-Delete-Article/"/>
    <url>/2023/04/20/Hexo-Release-OR-Delete-Article/</url>
    
    <content type="html"><![CDATA[<p><span style="color: #519D9E; ">关于如何在hexo博客上发布和删除博文</span></p><h2 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a><strong>创建文章</strong></h2><p>进入博客目录，在 &#x2F;source&#x2F;_posts 文件夹下直接建立一个.md文件</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo new “这里填入文章的标题”  </code></pre></figure><p>.md文件注意使用带有makedown语法的编辑器打开，对文章进行编辑，你可以在Hexo-&gt;Source-&gt;_post目录下看到你新创建的那个文章，还有一个配套的文件夹，里面放这边博文的图片资源</p><p>文章标题，日期，标签，分类</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  title: 文章标题  date: 2015-11-13 15:40:25  tags: 标签  categories: 分类  </code></pre></figure><p>文章插入图片需要用到一个Hexo的插件，首先cd到hexo的根目录下</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  npm install https://github.com/CodeFalling/hexo-asset-image –save  </code></pre></figure><p>然后把图片放入对应文章的配套文件夹下</p><p>如果要进行代码书写，代码样式可自行下载</p><h2 id="发布新建文章"><a href="#发布新建文章" class="headerlink" title="发布新建文章"></a><strong>发布新建文章</strong></h2><p>文章写好后，直接在git bash中执行以下命令即可直接发布文章</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo d -g  </code></pre></figure><p>如果发布的时候出现错误</p><p><code>ERROR Deployer not found: git</code></p><p>执行</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  npm install hexo-deployer-git –save  </code></pre></figure><h2 id="删除文章"><a href="#删除文章" class="headerlink" title="删除文章"></a><strong>删除文章</strong></h2><p>删除文章的过程一样也很简单，先删除本地文件，然后通过生成和部署命令进而将远程仓库中的文件也一并删除。具体来说，以最开始默认形成的helloworld.md这篇文章为例。</p><p>首先进入到source &#x2F; _post 文件夹中，找到helloworld.md文件，在本地直接执行删除。然后依次执行</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo d -g  </code></pre></figure><p>再去主页查看你就会发现你的博客上面已经空空如也了，这就是如何删除文章的方法。</p>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>命令</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Centos查看CPU核数命令</title>
    <link href="/2023/04/20/Centos-CPU-Check-Info/"/>
    <url>/2023/04/20/Centos-CPU-Check-Info/</url>
    
    <content type="html"><![CDATA[<h1 id="总核数-x3D-物理CPU个数-X-每颗物理CPU的核数"><a href="#总核数-x3D-物理CPU个数-X-每颗物理CPU的核数" class="headerlink" title="总核数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数"></a>总核数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数</h1><h1 id="总逻辑CPU数-x3D-物理CPU个数-X-每颗物理CPU的核数-X-超线程数"><a href="#总逻辑CPU数-x3D-物理CPU个数-X-每颗物理CPU的核数-X-超线程数" class="headerlink" title="总逻辑CPU数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数 X 超线程数"></a>总逻辑CPU数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数 X 超线程数</h1><h1 id="查看物理CPU个数"><a href="#查看物理CPU个数" class="headerlink" title="查看物理CPU个数"></a>查看物理CPU个数</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l  </code></pre></figure><h1 id="查看每个物理CPU中core的个数-即核数"><a href="#查看每个物理CPU中core的个数-即核数" class="headerlink" title="查看每个物理CPU中core的个数(即核数)"></a>查看每个物理CPU中core的个数(即核数)</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "cpu cores"| uniq  </code></pre></figure><h1 id="查看逻辑CPU的个数"><a href="#查看逻辑CPU的个数" class="headerlink" title="查看逻辑CPU的个数"></a>查看逻辑CPU的个数</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "processor"| wc -l  </code></pre></figure>]]></content>
    
    
    <categories>
      
      <category>SYSTEM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CENTOS</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
