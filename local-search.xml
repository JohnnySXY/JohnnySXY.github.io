<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Zabbix5.0版本Docker-compose.yml</title>
    <link href="/2023/04/23/Zabbix5-0%E7%89%88%E6%9C%ACDocker-compose-yml/"/>
    <url>/2023/04/23/Zabbix5-0%E7%89%88%E6%9C%ACDocker-compose-yml/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>鉴于网络中各个文章讲述的docker方式安装一套zabbix—server端都模糊不清及国内网络连接docker服务器拉取镜像一直无法成功的拉取完整镜像，遂分享自己经过测试和使用无异常的docker-compose文件，旨在让大家可以快速高效的部署一套即开即用的zabbix服务端。</p><h1 id="docker-compose配置分享"><a href="#docker-compose配置分享" class="headerlink" title="docker-compose配置分享"></a>docker-compose配置分享</h1><p>以下为<code>docker-compose.yml</code>文件，请根据自己的情况更改mysql密码及zabbix管理密码：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  version: "3"  services:    zabbix-db:      image: mysql:5.7      container_name: zabbix-db      environment:        - MYSQL_DATABASE=zabbix        - MYSQL_USER=zabbix        - MYSQL_PASSWORD=zabbix123        - MYSQL_ROOT_PASSWORD=Zabbix123      volumes:        - "$&#123;PWD&#125;/mysql:/var/lib/mysql"<pre><code class="hljs">zabbix-server-mysql:  image: zabbix/zabbix-server-mysql:ubuntu-5.0-latest  container_name: zabbix-server-mysql  environment:    - DB_SERVER_HOST=mysql    - MYSQL_DATABASE=zabbix    - MYSQL_USER=zabbix    - MYSQL_PASSWORD=zabbix123    - MYSQL_ROOT_PASSWORD=Zabbix123  volumes:    - &quot;$&#123;PWD&#125;/zabbix/alertscripts:/usr/lib/zabbix/alertscripts&quot;  ports:    - &quot;10051:10051&quot;  links:    - zabbix-db:mysql  depends_on:    - zabbix-db  zabbix-web-nginx-mysql:  image: zabbix/zabbix-web-nginx-mysql:ubuntu-5.0-latest  container_name: zabbix-web-nginx-mysql  environment:    - DB_SERVER_HOST=mysql    - MYSQL_DATABASE=zabbix    - MYSQL_USER=zabbix    - MYSQL_PASSWORD=zabbix123    - MYSQL_ROOT_PASSWORD=Zabbix123    - TZ=Asia/Shanghai    - PHP_TZ=Asia/Shanghai    ports:    - &quot;8082:8080&quot;  links:    - zabbix-db:mysql    - zabbix-server-mysql:zabbix-server  depends_on:    - zabbix-server-mysql  </code></pre><p>  networks:<br>    default:<br>      external:<br>        name: zabbix</p><p>  </p></code></pre><p></p></figure><p><span style="color: #519D9E; ">注：个人建议在启动前先docker pull下载对应docker镜像，因为在国内网络环境下有些惊喜无法正常下载</span><br>如遇无法下载或无法完整下载的镜像时，可以访问<a href="https://www.zabbix.com/container_images">Zabbix Docker images</a>Zabbix官网镜像地址跳转至docker镜像库中，在tags中选择自己需要的版本并在本地使用docker pull xxx 进行测试是否可以正常下载镜像</p><h1 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h1><h2 id="Mysql字符集导致zabbix无法插入中文"><a href="#Mysql字符集导致zabbix无法插入中文" class="headerlink" title="Mysql字符集导致zabbix无法插入中文"></a>Mysql字符集导致zabbix无法插入中文</h2><h3 id="1-查看当前数据库支持的字符集"><a href="#1-查看当前数据库支持的字符集" class="headerlink" title="1. 查看当前数据库支持的字符集"></a>1. 查看当前数据库支持的字符集</h3><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  mysql> show character set ;  <p>  +———-+———————————+———————+——–+  </p><p>  | Charset  | Description                     | Default collation   | Maxlen |  </p><p>  +———-+———————————+———————+——–+  </p><p>  | big5     | Big5 Traditional Chinese        | big5_chinese_ci     |      2 |  </p><p>  | dec8     | DEC West European               | dec8_swedish_ci     |      1 |  </p><p>  | cp850    | DOS West European               | cp850_general_ci    |      1 |  </p><p>  | hp8      | HP West European                | hp8_english_ci      |      1 |  </p><p>  | koi8r    | KOI8-R Relcom Russian           | koi8r_general_ci    |      1 |  </p><p>  | latin1   | cp1252 West European            | latin1_swedish_ci   |      1 |  </p><p>  | latin2   | ISO 8859-2 Central European     | latin2_general_ci   |      1 |  </p><p>  | swe7     | 7bit Swedish                    | swe7_swedish_ci     |      1 |  </p><p>  | ascii    | US ASCII                        | ascii_general_ci    |      1 |  </p><p>  | ujis     | EUC-JP Japanese                 | ujis_japanese_ci    |      3 |  </p><p>  | sjis     | Shift-JIS Japanese              | sjis_japanese_ci    |      2 |  </p><p>  | hebrew   | ISO 8859-8 Hebrew               | hebrew_general_ci   |      1 |  </p><p>  | tis620   | TIS620 Thai                     | tis620_thai_ci      |      1 |  </p><p>  | euckr    | EUC-KR Korean                   | euckr_korean_ci     |      2 |  </p><p>  | koi8u    | KOI8-U Ukrainian                | koi8u_general_ci    |      1 |  </p><p>  | gb2312   | GB2312 Simplified Chinese       | gb2312_chinese_ci   |      2 |  </p><p>  | greek    | ISO 8859-7 Greek                | greek_general_ci    |      1 |  </p><p>  | cp1250   | Windows Central European        | cp1250_general_ci   |      1 |  </p><p>  | gbk      | GBK Simplified Chinese          | gbk_chinese_ci      |      2 |  </p><p>  | latin5   | ISO 8859-9 Turkish              | latin5_turkish_ci   |      1 |  </p><p>  | armscii8 | ARMSCII-8 Armenian              | armscii8_general_ci |      1 |  </p><p>  | utf8     | UTF-8 Unicode                   | utf8_general_ci     |      3 |  </p><p>  | ucs2     | UCS-2 Unicode                   | ucs2_general_ci     |      2 |  </p><p>  | cp866    | DOS Russian                     | cp866_general_ci    |      1 |  </p><p>  | keybcs2  | DOS Kamenicky Czech-Slovak      | keybcs2_general_ci  |      1 |  </p><p>  | macce    | Mac Central European            | macce_general_ci    |      1 |  </p><p>  | macroman | Mac West European               | macroman_general_ci |      1 |  </p><p>  | cp852    | DOS Central European            | cp852_general_ci    |      1 |  </p><p>  | latin7   | ISO 8859-13 Baltic              | latin7_general_ci   |      1 |  </p><p>  | utf8mb4  | UTF-8 Unicode                   | utf8mb4_general_ci  |      4 |  </p><p>  | cp1251   | Windows Cyrillic                | cp1251_general_ci   |      1 |  </p><p>  | utf16    | UTF-16 Unicode                  | utf16_general_ci    |      4 |  </p><p>  | utf16le  | UTF-16LE Unicode                | utf16le_general_ci  |      4 |  </p><p>  | cp1256   | Windows Arabic                  | cp1256_general_ci   |      1 |  </p><p>  | cp1257   | Windows Baltic                  | cp1257_general_ci   |      1 |  </p><p>  | utf32    | UTF-32 Unicode                  | utf32_general_ci    |      4 |  </p><p>  | binary   | Binary pseudo charset           | binary              |      1 |  </p><p>  | geostd8  | GEOSTD8 Georgian                | geostd8_general_ci  |      1 |  </p><p>  | cp932    | SJIS for Windows Japanese       | cp932_japanese_ci   |      2 |  </p><p>  | eucjpms  | UJIS for Windows Japanese       | eucjpms_japanese_ci |      3 |  </p><p>  | gb18030  | China National Standard GB18030 | gb18030_chinese_ci  |      4 |  </p><p>  +———-+———————————+———————+——–+  </p><p>  41 rows in set (0.00 sec)</p><p>  </p></code></pre><p></p></figure><p>在支持列表中我们可以看到眼熟的ascii，gbk，utf8，utf8mb4等，以及下面会出现的latin1。</p><p><strong>着重强调</strong>：utf8和utf8mb4，在列表可以看到Maxlen最大长度一栏，utf8最大长度为3字节，所以utf8有个别名叫utf8mb3，两者是一个意思。而utf8mb4最大长度4字节，可以理解为utf8mb4是utf8的扩展，毕竟多一个字节可以多存很多数据，比如特殊的字符或者emoji表情就需要utf8mb4字符集。在实际生产环境中也都是使用utf8mb4字符集。</p><h4 id="1-1-查看当前数据库使用的字符集"><a href="#1-1-查看当前数据库使用的字符集" class="headerlink" title="1.1 查看当前数据库使用的字符集"></a>1.1 查看当前数据库使用的字符集</h4><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  mysql> show variables like '%character%' ;  <p>  +————————–+—————————-+  </p><p>  | Variable_name            | Value                      |  </p><p>  +————————–+—————————-+  </p><p>  | character_set_client     | utf8                       |  </p><p>  | character_set_connection | utf8                       |  </p><p>  | character_set_database   | latin1                     |  </p><p>  | character_set_filesystem | binary                     |  </p><p>  | character_set_results    | utf8                       |  </p><p>  | character_set_server     | latin1                     |  </p><p>  | character_set_system     | utf8                       |  </p><p>  | character_sets_dir       | &#x2F;usr&#x2F;share&#x2F;mysql&#x2F;charsets&#x2F; |  </p><p>  +————————–+—————————-+  </p><p>  8 rows in set (0.00 sec)</p><p>  </p></code></pre><p></p></figure><p><strong>参数解释</strong>：</p><p>官方文档：</p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html">https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html</a></p><table><thead><tr><th>Rate tiers</th><th>Pricing</th></tr></thead><tbody><tr><td>character_set_client</td><td>客户端请求数据的字符集</td></tr><tr><td>character_set_connection</td><td>从客户端接收到数据，然后传输的字符集</td></tr><tr><td>character_set_database</td><td>默认数据库的字符集，无论默认数据库如何改变，都是这个字符集；如果没有默认数据库，那就使用 character_set_server指定的字符集，这个变量建议由系统自己管理，不要人为定义</td></tr><tr><td>character_set_filesystem</td><td>把os上文件名转化成此字符集，即把character_set_client转换character_set_filesystem，默认binary是不做任何转换的</td></tr><tr><td>character_set_results</td><td>结果集的字符集</td></tr><tr><td>character_set_server</td><td>数据库服务器的默认字符集</td></tr><tr><td>character_set_system</td><td>这个值总是utf8，不需要设置，是为存储系统元数据的字符集</td></tr></tbody></table><p>通过以上可以看到数据库服务器默认的字符集是latin1，此数据集是ASCII的扩展，但是最大长度还是1字节，无法存储汉字，特殊符号等；需要将默认的latin1修改为常用的utf8mb4字符集。</p><p><strong>注意</strong>：mysql在5.5.3版本之后才支持utf8mb4.</p><h4 id="1-2-查看当前某个数据库使用的字符集"><a href="#1-2-查看当前某个数据库使用的字符集" class="headerlink" title="1.2 查看当前某个数据库使用的字符集"></a>1.2 查看当前某个数据库使用的字符集</h4><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  mysql> show create database test ;  <p>  +———-+——————————————————————+  </p><p>  | Database | Create Database                                                  |  </p><p>  +———-+——————————————————————+  </p><p>  | test     | CREATE DATABASE <code>test</code> &#x2F;*!40100 DEFAULT CHARACTER SET utf8mb4 *&#x2F; |  </p><p>  +———-+——————————————————————+  </p><p>  1 row in set (0.00 sec)</p><p>  </p></code></pre><p></p></figure><h3 id="2-字符集转换"><a href="#2-字符集转换" class="headerlink" title="2. 字符集转换"></a>2. 字符集转换</h3><h4 id="1-更改数据库默认字符集"><a href="#1-更改数据库默认字符集" class="headerlink" title="1. 更改数据库默认字符集"></a>1. 更改数据库默认字符集</h4><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  [root@localhost ~]# cp /etc/my.cnf /etc/my.cnf.bak    //备份mysql配置文件my.cnf  <p>  [root@localhost ~]# vim &#x2F;etc&#x2F;my.cnf<br>  [mysqld]<br>  character-set-server&#x3D;utf8         &#x2F;&#x2F;新增配置项<br>  datadir&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql<br>  socket&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock<br>  symbolic-links&#x3D;0<br>  log-error&#x3D;&#x2F;var&#x2F;log&#x2F;mysqld.log<br>  pid-file&#x3D;&#x2F;var&#x2F;run&#x2F;mysqld&#x2F;mysqld.pid  </p><p>  [client]                &#x2F;&#x2F;新增配置项<br>  default-character-set&#x3D;utf8     &#x2F;&#x2F;新增配置项  </p><p>  [mysql]                     &#x2F;&#x2F;新增配置项<br>  default-character-set&#x3D;utf8     &#x2F;&#x2F;新增配置项  </p><p>  [root@localhost ~]# service mysqld restart        &#x2F;&#x2F;重启mysql服务<br>  停止 mysqld：                                              [确定]<br>  正在启动 mysqld：                                          [确定]  </p><p>  [root@localhost ~]# mysql -uroot -p123qqq…A<br>  …<br>  mysql&gt; show variables like ‘%char%’;<br>  +————————————–+—————————-+<br>  | Variable_name                        | Value                      |<br>  +————————————–+—————————-+<br>  | character_set_client                 | utf8                       |<br>  | character_set_connection             | utf8                       |<br>  | character_set_database               | utf8                       |<br>  | character_set_filesystem             | binary                     |<br>  | character_set_results                | utf8                       |<br>  | character_set_server                 | utf8                       |<br>  | character_set_system                 | utf8                       |<br>  | character_sets_dir                   | &#x2F;usr&#x2F;share&#x2F;mysql&#x2F;charsets&#x2F; |<br>  | validate_password_special_char_count | 1                          |<br>  +————————————–+—————————-+<br>  9 rows in set (0.00 sec)</p><p>  </p></code></pre><p></p></figure><h4 id="2-导出数据（数据库已安装并配置了zabbix情况下）"><a href="#2-导出数据（数据库已安装并配置了zabbix情况下）" class="headerlink" title="2. 导出数据（数据库已安装并配置了zabbix情况下）"></a>2. 导出数据（数据库已安装并配置了zabbix情况下）</h4><p>mysqldump -uroot -p  库名 &gt; zabbix.sql</p><h4 id="3-替换数据，查看sql文件中的内容，寻找默认的字符集并改为utf8"><a href="#3-替换数据，查看sql文件中的内容，寻找默认的字符集并改为utf8" class="headerlink" title="3. 替换数据，查看sql文件中的内容，寻找默认的字符集并改为utf8"></a>3. 替换数据，查看sql文件中的内容，寻找默认的字符集并改为utf8</h4><p>sed -i ‘s&#x2F;latin1&#x2F;utf8&#x2F;g’ zabbix.sql</p><h4 id="4-导入更换字符集和原有数据"><a href="#4-导入更换字符集和原有数据" class="headerlink" title="4. 导入更换字符集和原有数据"></a>4. 导入更换字符集和原有数据</h4><p>Source zabbix.sql</p>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>监控</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kafka集群实战与原理分析线上问题优化</title>
    <link href="/2023/04/21/Kafka%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98%E4%B8%8E%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E4%BC%98%E5%8C%96/"/>
    <url>/2023/04/21/Kafka%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98%E4%B8%8E%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="Kafka-集群实战与原理分析线上问题优化"><a href="#Kafka-集群实战与原理分析线上问题优化" class="headerlink" title="Kafka 集群实战与原理分析线上问题优化"></a>Kafka 集群实战与原理分析线上问题优化</h1><h2 id="一、为什么使用消息队列"><a href="#一、为什么使用消息队列" class="headerlink" title="一、为什么使用消息队列?"></a>一、为什么使用消息队列?</h2><h3 id="1-1-Kafka知识点思维导图"><a href="#1-1-Kafka知识点思维导图" class="headerlink" title="1.1 Kafka知识点思维导图"></a>1.1 Kafka知识点思维导图</h3><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-LinuxKafka%E9%9B%86%E7%BE%A4%E5%AE%9E%E6%88%98.jpg" alt="Kafka集群实战"></p><p>以电商为业务背景</p><p>消息队列解决的具体问题是什么？ – 通信问题。</p><h3 id="1-2-使用同步的通讯方式来解决多个服务之间的通讯"><a href="#1-2-使用同步的通讯方式来解决多个服务之间的通讯" class="headerlink" title="1.2 使用同步的通讯方式来解决多个服务之间的通讯"></a>1.2 使用同步的通讯方式来解决多个服务之间的通讯</h3><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linux%E8%AE%A2%E5%8D%95%E5%9C%BA%E6%99%AF.png" alt="订单场景"></p><p>同步的通讯方式会存在性能和稳定性的问题。</p><h3 id="1-3-使用异步通讯方式"><a href="#1-3-使用异步通讯方式" class="headerlink" title="1.3 使用异步通讯方式"></a>1.3 使用异步通讯方式</h3><p>在业务的上游与下游间加入 通讯模块 （消息队列 存储消息的队列）</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linux%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E9%80%9A%E8%AE%AF%E6%96%B9%E5%BC%8F.png" alt="消息队列通讯方式"></p><p>最终一致性</p><p>针对同步的通讯方式来说，异步的方式，可以让上游快速成功，极大提高了系统的吞吐量。而且在分布式系统中，通过下游多个服务的分布式事务保障，也能保证业务执行之后的最终一致性。</p><h2 id="二、消息队列的流派"><a href="#二、消息队列的流派" class="headerlink" title="二、消息队列的流派"></a>二、消息队列的流派</h2><h3 id="2-1-什么是MQ-？"><a href="#2-1-什么是MQ-？" class="headerlink" title="2.1 什么是MQ ？"></a>2.1 什么是MQ ？</h3><p>Message Queue（MQ），消息队列中间件。</p><p>很多人都说：</p><p>MQ 通过将消息的发送和接收分离来实现应用程序的异步和解偶，这个给人的直觉是——MQ 是异步的，用来解耦的，但是这个只是 MQ 的效果而不是目的。</p><p>MQ 真正的目的是为了通讯，屏蔽底层复杂的通讯协议，定义了一套应用层的、更加简单的通讯协议。</p><p>一个分布式系统中两个模块之间通讯要么是 HTTP，要么是自己开发的 TCP，但是这两种协议其实都是原始的协议。</p><p>HTTP 协议很难实现两端通讯——模块 A 可以调用 B，B 也可以主动调用 A，如果要做到这个两端都要背上 WebServer，而且还不支持长连接（HTTP 2.0 的库根本找不到）。<br>TCP 就更加原始了，粘包、心跳、私有的协议，想一想头皮就发麻。</p><p>MQ 所要做的就是在这些协议之上构建一个简单的“协议”——生产者&#x2F;消费者模型。</p><p>MQ 带给我的“协议”不是具体的通讯协议，而是更高层次通讯模型。<br>它定义了两个对象——发送数据的叫生产者，接收数据的叫消费者；<br>提供一个 SDK 让我们可以定义自己的生产者和消费者实现消息通讯而无视底层通讯协议。</p><h3 id="2-2-中间件选型"><a href="#2-2-中间件选型" class="headerlink" title="2.2 中间件选型"></a>2.2 中间件选型</h3><p>目前消息队列的中间件选型有很多种：</p><p>rabbit MQ：内部可玩性（功能性）是非常强的</p><p>rocket MQ :阿里内部大神根据Kafka的内部执行原理，手写的一个消息中间件。性能比肩kafka，除此之外，在功能上封装了更多的功能。（消息的逆序）<br>kafka：全球消息处理性能最快的一款MQ（纯粹）</p><p>zeroMQ</p><p>这些消息队列中间件有什么区别？</p><p>我们把消息队列分为两种</p><p>MQ，分为有Broker的MQ，和没有Broker的MQ。<br>Broker，代理，经纪人的意思。</p><h4 id="2-2-1-有broker"><a href="#2-2-1-有broker" class="headerlink" title="2.2.1 有broker"></a>2.2.1 有broker</h4><p>有broker的MQ<br>这个流派通常有一台服务器作为Broker，所有的消息都通过它中转。生产者把消息发送给它就结束自己的任务了，Broker则把消息主动推送给消费者（或者消费者主动轮询）。</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linux%E6%9C%89broker.png" alt="有broker"></p><p>重topic：Kafka 、RocketMQ 、 ActiveMQ<br>整个broker，依据topic来进行消息的中转，在重topic的消息队列里必然需要topic的存在</p><p>轻topic：RabbitMQ<br>topic只是其一种中转模式。</p><h4 id="2-2-2-无broker"><a href="#2-2-2-无broker" class="headerlink" title="2.2.2 无broker"></a>2.2.2 无broker</h4><p>在生产者和消费者之间没有使用broker，例如zeroMQ，直接使用socket进行通信</p><p>无broker的MQ代表是ZeroMQ，该作者非常睿智，他非常敏锐的意识到–MQ是更高级的Socket</p><p>它是解决通信问题的。所以ZeroMQ被设计成了一个“库”而不是一个中间件，这种实现也可以达到–没有Broker的目的。</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linux%E6%97%A0broker.png" alt="无broker"></p><h2 id="三、Kafka的基本知识"><a href="#三、Kafka的基本知识" class="headerlink" title="三、Kafka的基本知识"></a>三、Kafka的基本知识</h2><p>Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统.</p><p>它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：</p><p>比如基于hadoop的批处理系统、低延迟的实时系统、storm&#x2F;Spark流式处理引擎，web&#x2F;nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p><h3 id="3-1-Kafka的特性"><a href="#3-1-Kafka的特性" class="headerlink" title="3.1 Kafka的特性:"></a>3.1 Kafka的特性:</h3><p>高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。</p><p>可扩展性：kafka集群支持热扩展</p><p>持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失</p><p>容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）</p><p>高并发：支持数千个客户端同时读写</p><h3 id="3-2-Kafka的使用场景"><a href="#3-2-Kafka的使用场景" class="headerlink" title="3.2 Kafka的使用场景"></a>3.2 Kafka的使用场景</h3><p>日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等。</p><p>消息系统：解耦和生产者和消费者、缓存消息等。</p><p>用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。</p><p>运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。</p><h3 id="3-2-基本概念"><a href="#3-2-基本概念" class="headerlink" title="3.2 基本概念"></a>3.2 基本概念</h3><p>kafka是一个分布式的，分区的消息(官方称之为commit log)服务。它提供一个消息系统应该具备的功能，但是确有着独特的设计。</p><p>首先，让我们来看一下基础的消息(Message)相关术语：</p><p>kafka 中有这么些复杂的概念</p><table><thead><tr><th>名称</th><th>解释</th></tr></thead><tbody><tr><td>Broker</td><td>消息中间件处理节点，一个kafka节点就是一个broker，一个或多个Broker可以组成一个kafka集群</td></tr><tr><td>Topic</td><td>kafka根据Topic对消息进行分类，发布到kafka集群的每条消息都需要指定一个Topic</td></tr><tr><td>Producer</td><td>消息生产者，向Broker发送消息的客户端</td></tr><tr><td>Consumer</td><td>消息消费者，从Broker读取消息的客户端</td></tr><tr><td>ConsumerGroup</td><td>个consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer消费，但是一个Consumer Group中只能有一个consumer能消费该消息</td></tr><tr><td>Partition</td><td>物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的</td></tr></tbody></table><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.png" alt="kafka基本概念"></p><h3 id="3-3-创建主题topic"><a href="#3-3-创建主题topic" class="headerlink" title="3.3 创建主题topic"></a>3.3 创建主题topic</h3><p>topic kafka消息逻辑的划分</p><p>topic是什么概念? topic可以实现消息的分类，不同消费者订阅不同的topic。</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linux20220111104851.png"></p><p>执行以下命令创建名为”test”的topic，这个topic只有一个partition，并且备份因子也设置为1;</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-topics.sh --create --zookeeper 172.16.253.35:2181 --replication-factor 1 --partitions 1 --topic test  </code></pre></figure><p>查看当前kafka内有哪些topic</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./ kafka-topics.sh --list --zookeeper 172.16.253.35:2181  </code></pre></figure><h3 id="3-4-发送消息"><a href="#3-4-发送消息" class="headerlink" title="3.4 发送消息"></a>3.4 发送消息</h3><p>kafka自带了一个producer命令客户端，可以从本地文件中读取内容，或者我们也可以以命令行中直接输入内容，并将这些内容以消息的形式发送到kafka集群中。在默认情况下，每一个行会被当做成一个独立的消息。</p><p>使用kafka的发送消息的客户端，指定发送到的kafka服务器地址和topic</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-producer.sh --broker-list 10.31.167.10:9092 --topic test  </code></pre></figure><h3 id="3-5-消费消息"><a href="#3-5-消费消息" class="headerlink" title="3.5 消费消息"></a>3.5 消费消息</h3><p>对于consumer, kafka同样也携带了一个命令行客户端，会将获取到内容在命令中进行输出，默认是消费最新的消息。使用kafka的消费者消息的客户端，从指定kafka服务器的指定topic中消费消息</p><p>方式一:从当前主题中最后一条消息的offset（偏移量）+1开始消费</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --topic test  </code></pre></figure><p>方式二∶从当前主题中的第一条消息开始消费</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafxa-console-consumer.sh --bootstrap-server 10.31.167.10:9092 --from-beginning --topic test  </code></pre></figure><h3 id="3-6-关于消息的细节"><a href="#3-6-关于消息的细节" class="headerlink" title="3.6 关于消息的细节"></a>3.6 关于消息的细节</h3><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E6%B6%88%E8%B4%B9%E7%BB%86%E8%8A%82.png"></p><p>生产者将消息发送给broker，broker会将消息保存在本地的日志文件中</p><p><code>/usr/ local/kafka/data/kafka-logs/主题-分区/0000000o.log</code></p><p>消息的保存是有序的，通过offset偏移量来描述消息的有序性</p><p>消费者消费消息时也是通过offset来描述当前要消费的那条消息的位置</p><h3 id="3-7-单播消息"><a href="#3-7-单播消息" class="headerlink" title="3.7 单播消息"></a>3.7 单播消息</h3><p>在一个kafka的topic中，启动两个消费者，一个生产者，问:生产者发送消息，这条消息是否同时会被两个消费者消费?</p><p>如果多个消费者在同一个消费组，那么只有一个消费者可以收到订阅的topic中的消息。换言之，同一个消费组中只能有一个消费者收到一个topic中的消息。</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroup --topic test  </code></pre></figure><h3 id="3-8-多播消息"><a href="#3-8-多播消息" class="headerlink" title="3.8 多播消息"></a>3.8 多播消息</h3><p>不同的消费组订阅同一个topic，那么不同的消费组中只有一个消费者能收到消息。实际上也是多个消费组中的多个消费者收到了同一个消息。</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroupl --topic test  </code></pre></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer.sh --bootstrap-server 172.16.253.38:9092--consumer-property group.id=testGroup2 --topic test  </code></pre></figure><p>下图就是描述多播和单播消息的区别:</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%A4%9A%E6%92%AD%E4%B8%8E%E5%8D%95%E6%92%AD%E6%B6%88%E6%81%AF%E7%9A%84%E5%8C%BA%E5%88%AB.png"></p><h3 id="3-9-查看消费组的详细信息"><a href="#3-9-查看消费组的详细信息" class="headerlink" title="3.9 查看消费组的详细信息"></a>3.9 查看消费组的详细信息</h3><p>通过以下命令可以查看到消费组的详细信息︰</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-consumer-groups.sh --bootstrap-server 172.16.253.38:9092 --describe --group testGroup  </code></pre></figure><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E6%9F%A5%E7%9C%8B%E6%B6%88%E8%B4%B9%E7%BB%84%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF.png"></p><p>重点关注以下几个信息∶</p><ul><li>current-offset:最后被消费的消息的偏移量</li><li>Log-end-offset:消息总量(最后一条消息的偏移量)</li><li>Lag:积压了多少条消息</li></ul><h2 id="四、Kafka-中主题和分区的概念"><a href="#四、Kafka-中主题和分区的概念" class="headerlink" title="四、Kafka 中主题和分区的概念"></a>四、Kafka 中主题和分区的概念</h2><h3 id="4-1-主题Topic"><a href="#4-1-主题Topic" class="headerlink" title="4.1 主题Topic"></a>4.1 主题Topic</h3><p>主题-topic在kafka中是一个逻辑的概念，kafka通过topic将消息进行分类。不同的topic会被订阅该topic的消费者消费。</p><p>但是有一个问题，如果说这个topic中的消息非常非常多，多到需要几T来存，因为消息是会被保存到log日志文件中的。为了解决这个文件过大的问题, kafka提出了Partition分区的概念</p><h3 id="4-2-partition-分区"><a href="#4-2-partition-分区" class="headerlink" title="4.2 partition 分区"></a>4.2 partition 分区</h3><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%88%86%E5%8C%BA.png"></p><p>1)分区的概念</p><p>通过partition将一个topic中的消息分区来存储。</p><p>这样的好处有多个:</p><ul><li><p>分区存储，可以解决统一存储文件过大的问题</p></li><li><p>提供了读写的吞吐量:读和写可以同时在多个分区中进行</p></li></ul><p>2)创建多分区的主题</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-topics.sh --create --zokeeper 172.16.253.35:2181 --replication-factor l --partitions 2 --topic test1  </code></pre></figure><h3 id="4-3-kafka-中消息日志文件中保存的内容"><a href="#4-3-kafka-中消息日志文件中保存的内容" class="headerlink" title="4.3 kafka 中消息日志文件中保存的内容"></a>4.3 kafka 中消息日志文件中保存的内容</h3><p><code>. 00000.log</code>:这个文件中保存的就是消息<br>_consumer_offsets-49</p><p>kafka内部自己创建了_consumer_offsets主题包含了50个分区。这个主题用来存放消费者消费某个主题的偏移量。</p><p>因为每个消费者都会自己维护着消费的主题的偏移量，也就是说每个消费者会把消费的主题的偏移量自主上报给kafka中的默认主题consumer_offsets。因此kafka为了提升这个主题的并发性，默认设置了50个分区。(可以通过offsets.topic.num.paritions设置)，这样可以通过加机器的方式抗大并发。</p><ul><li><p>提交到哪个分区︰通过hash函数: hash(consumerGroupld) %_consumer_offsets主题的分区数</p></li><li><p>提交到该主题中的内容是: key是consumerGroupld+topic+分区号，value就是当前offset的值</p></li><li><p>文件中保存的消息，kafka会定期清理topic里的消息，最后就保留最新的那条数据默认保存7天。七天到后消息会被删除。</p></li></ul><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-offsets50%E9%BB%98%E8%AE%A4%E4%B8%BB%E9%A2%98.png"></p><h2 id="五、Kafka集群操作"><a href="#五、Kafka集群操作" class="headerlink" title="五、Kafka集群操作"></a>五、Kafka集群操作</h2><h3 id="5-1-搭建kafka集群（三个broker）"><a href="#5-1-搭建kafka集群（三个broker）" class="headerlink" title="5.1 搭建kafka集群（三个broker）"></a>5.1 搭建kafka集群（三个broker）</h3><p>创建三个<code>server.properties</code>文件</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  \#0 1 2  broker.id=2  <p>  #9092 9093 9094<br>  listeners&#x3D;PLAINTEXT :&#x2F;&#x2F;192.168.65.60:9094  </p><p>  #kafka-logs kafka-logs-1 kafka-logs-2<br>  log.dir&#x3D;&#x2F;usr&#x2F; local&#x2F; data&#x2F; kafka-logs-2<br>  </p></code></pre><p></p></figure><p>通过命令来启动三台broker</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./ kafka-server-start.sh -daemon ../config/server.properties  ./ kafka-server-start.sh -daemon ../config/server1.properties  ./ kafka-server-start.sh -daemon ../config/server2.properties  </code></pre></figure><p>校验是否启动成功</p><p><code>进入到zk中查看/brokers/ids中过是否有三个znode (0,1,2)</code></p><h3 id="5-2-副本的概念"><a href="#5-2-副本的概念" class="headerlink" title="5.2 副本的概念"></a>5.2 副本的概念</h3><p>在创建主题时，除了指明了主题的分区数以外，还指明了副本数，那么副本是一个什么概念呢?</p><p>副本是为了为主题中的分区创建多个备份，多个副本在kafka集群的多个broker中，会有一个副本作为leader，其他是follower。 生产者与消费者只会与leader交互消息，而follower只会与leader保持同步以备不时之需。</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%89%AF%E6%9C%AC%E6%A6%82%E5%BF%B5.png"></p><ul><li><p>leader: kafka的写和读的操作，都发生在leader上。leader负责把数据同步给follower。当leader挂了，经过主从选举，从多个follower中选举产生一个新的leader</p></li><li><p>follower： 接收leader的同步的数据</p></li><li><p>isr: 可以同步和已同步的节点会被存入到isr集合中。这里有一个细节︰如果isr中的节点性能较差，会被提出isr集合。)</p></li></ul><p><strong>理解:</strong> 集群中有多个broker，创建主题时可以指明主题有多个分区(把消息拆分到不同的分区中存储)，可以为分区创建多个副本，不同的副本存放在不同的broker里。</p><h3 id="5-3-关于集群消费"><a href="#5-3-关于集群消费" class="headerlink" title="5.3 关于集群消费"></a>5.3 关于集群消费</h3><p>向集群发送消息∶</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer . sh --bootstrap-server 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroupl --topic my-replicated-topic  </code></pre></figure><p>从集群中消费消息</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-producer .sh --broker-list 172.16.253.38:9092,172.16.253.38:9093,172.16.253.38:9094 --topicmy-replicated-topic  </code></pre></figure><p>指定消费组来消费消息</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  ./kafka-console-consumer .sh --bootstrap-server 172.16.253.38∶9092,172.16.253.38:9093,172.16.253.38:9094 --from-beginning --consumer-property group.id=testGroupl --topic my-replicated-topic  </code></pre></figure><h3 id="5-4-分区分消费组的集群消费中的细节"><a href="#5-4-分区分消费组的集群消费中的细节" class="headerlink" title="5.4 分区分消费组的集群消费中的细节"></a>5.4 分区分消费组的集群消费中的细节</h3><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%88%86%E5%8C%BA%E5%88%86%E6%B6%88%E8%B4%B9%E7%BB%84%E7%9A%84%E9%9B%86%E7%BE%A4%E6%B6%88%E8%B4%B9%E4%B8%AD%E7%9A%84%E7%BB%86%E8%8A%82.png"></p><ol><li>一个partition只能被一个消费组中的一个消费者消费，目的是为了保证消费的顺序性，但是多个partion的多个消费者消费的总的顺序性是得不到保证的，那怎么做到消费的总顺序性呢?</li><li>partition的数量决定了消费组中消费者的数量，建议同一个消费组中消费者的数量不要超过partition的数量，否则多的消费者消费不到消息</li><li>如果消费者挂了，那么会触发rebalance机制（后面介绍)，会让其他消费者来消费该分区</li></ol><h2 id="六、专题1-Kafka-集群Controller-、Rebalance-和HW"><a href="#六、专题1-Kafka-集群Controller-、Rebalance-和HW" class="headerlink" title="六、专题1 Kafka 集群Controller 、Rebalance 和HW"></a>六、专题1 Kafka 集群Controller 、Rebalance 和HW</h2><h3 id="6-1-controller"><a href="#6-1-controller" class="headerlink" title="6.1 controller"></a>6.1 controller</h3><p>集群中谁来充当controller</p><ol><li><p>每个broker启动时会向zk创建一个临时序号节点，获得的序号最小的那个broker将会作为集群中的controller，负责这么几件事:</p></li><li><p>当集群中有一个副本的leader挂掉，需要在集群中选举出一个新的leader，选举的规则是从isr集合中最左边获得。</p></li><li><p>当集群中有broker新增或减少，controller会同步信息给其他broker</p></li></ol><h3 id="6-2-rebalance机制"><a href="#6-2-rebalance机制" class="headerlink" title="6.2 rebalance机制"></a>6.2 rebalance机制</h3><p>**前提:**消费组中的消费者没有指明分区来消费</p><p>**触发的条件:**当消费组中的消费者和分区的关系发生变化的时候</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-rebalance%E6%9C%BA%E5%88%B6.png"></p><p>**分区分配的策略:**在rebalance之前， 分区怎么分配会有这么三种策略</p><ul><li><p>range: 根据公示计算得到每个消费消费哪几个分区:前面的消费者是分区总数&#x2F;消费<br>者数量+1,之后的消费者是分区总数&#x2F;消费者数量.</p></li><li><p>轮询:大家轮着来</p></li><li><p>sticky: 粘合策略，如果需要rebalance, 会在之前已分配的基础上调整，不会改变之前的分配情况。如果这个策略没有开，那么就要进行全部的重新分配。建议开启。</p></li></ul><h2 id="七、专题2-Kafka中的优化问题-面试问题"><a href="#七、专题2-Kafka中的优化问题-面试问题" class="headerlink" title="七、专题2 Kafka中的优化问题(面试问题)"></a>七、专题2 Kafka中的优化问题(面试问题)</h2><h3 id="7-1-如何防止消息丢失"><a href="#7-1-如何防止消息丢失" class="headerlink" title="7.1 如何防止消息丢失"></a>7.1 如何防止消息丢失</h3><p>⽣产者：</p><ol><li>使⽤同步发送</li><li>把ack设成1（leader 成功写入）或者all(所有broker完成同步)，并且设置同步的分区数&gt;&#x3D;2<br>消费者：把⾃动提交改成⼿动提交</li></ol><h3 id="7-2如何防⽌重复消费"><a href="#7-2如何防⽌重复消费" class="headerlink" title="7.2如何防⽌重复消费"></a>7.2如何防⽌重复消费</h3><p>在防⽌消息丢失的⽅案中，如果⽣产者发送完消息后，因为⽹络抖动，没有收到ack，但实际 上broker已经收到了。</p><p>此时⽣产者会进⾏重试，于是broker就会收到多条相同的消息，⽽造成消费者的重复消费。</p><p><strong>怎么解决：</strong></p><p>⽣产者关闭重试：会造成丢消息（不建议）</p><p>消费者解决⾮幂等性消费问题： 所谓的幂等性：多次访问的结果是⼀样的。</p><p>对于rest的请求（get（幂等）、post（⾮幂 等）、put（幂等）、delete（幂等））</p><p>幂等：多次访问的结果是一样的</p><p><strong>解决⽅案：</strong><br>在数据库中创建联合主键，防⽌相同的主键 创建出多条记录<br>使⽤分布式锁，以业务id为锁。保证只有⼀条记录能够创建成功</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%A6%82%E4%BD%95%E9%98%B2%E2%BD%8C%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9.png"></p><h3 id="7-3-如何做到消息的顺序消费"><a href="#7-3-如何做到消息的顺序消费" class="headerlink" title="7.3 如何做到消息的顺序消费"></a>7.3 如何做到消息的顺序消费</h3><ul><li><p>⽣产者：保证消息按顺序消费，且消息不丢失——使⽤同步的发送，ack设置成⾮0的 值。</p></li><li><p>消费者：主题只能设置⼀个分区，消费组中只能有⼀个消费者</p></li></ul><p>kafka的顺序消费使⽤场景不多，因为牺牲掉了性能，但是⽐如rocketmq在这⼀块有专⻔的功能已设计好</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%A6%82%E4%BD%95%E5%81%9A%E5%88%B0%E6%B6%88%E6%81%AF%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%B6%88%E8%B4%B9.png"></p><h3 id="7-4-如何解决消息积压问题"><a href="#7-4-如何解决消息积压问题" class="headerlink" title="7.4 如何解决消息积压问题"></a>7.4 如何解决消息积压问题</h3><p>1）消息积压问题的出现</p><p>消息的消费者的消费速度远赶不上⽣产者的⽣产消息的速度，导致kafka中有⼤量的数据没有被消费。</p><p>随着没有被消费的数据堆积越多，消费者寻址的性能会越来越差，最后导致整个 kafka对外提供的服务的性能很差，从⽽造成其他服务也访问速度变慢，造成服务雪崩。</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E9%97%AE%E9%A2%98%E7%9A%84%E5%87%BA%E7%8E%B0.png"></p><p>2）消息积压的解决⽅案</p><ol><li><p>在这个消费者中，使⽤多线程，充分利⽤机器的性能进⾏消费消息。</p></li><li><p>通过业务的架构设计，提升业务层⾯消费的性能。</p></li><li><p>创建多个消费组，多个消费者，部署到其他机器上，⼀起消费，提⾼消费者的消费速度</p></li></ol><p>创建⼀个消费者，该消费者在kafka另建⼀个主题，配上多个分区，多个分区再配上多个 消费者。该消费者将poll下来的消息，不进⾏消费，直接转发到新建的主题上。此时，新 的主题的多个分区的多个消费者就开始⼀起消费了。——不常⽤</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E7%9A%84%E8%A7%A3%E5%86%B3%E2%BD%85%E6%A1%88.png"></p><h3 id="5-实现延时队列的效果"><a href="#5-实现延时队列的效果" class="headerlink" title="5.实现延时队列的效果"></a>5.实现延时队列的效果</h3><p>1）应⽤场景 订单创建后，超过30分钟没有⽀付，则需要取消订单，这种场景可以通过延时队列来实现</p><p>2）具体⽅案</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka%E5%AE%9E%E7%8E%B0%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97%E7%9A%84%E6%95%88%E6%9E%9C.png"></p><ol><li><p>kafka中创建创建相应的主题</p></li><li><p>消费者消费该主题的消息(轮询)</p></li><li><p>消费者消费消息时判断消息的创建时间和当前时间是否超过30分钟(前提是订单没支付)</p></li><li><p>如果是:去数据库中修改订单状态为已取消</p></li><li><p>如果否:记录当前消息的offset,并不再继续消费之后的消息。等待1分钟后，再次向kafka拉取该offset及之后的消<br>息，继续进行判断，以此反复。</p></li></ol><h2 id="八、Kafka-eagle监控平台"><a href="#八、Kafka-eagle监控平台" class="headerlink" title="八、Kafka-eagle监控平台"></a>八、Kafka-eagle监控平台</h2><h3 id="8-1-搭建"><a href="#8-1-搭建" class="headerlink" title="8.1 搭建"></a>8.1 搭建</h3><p>去kafka-eagle官⽹下载压缩包<br><a href="http://download.kafka-eagle.org/">http://download.kafka-eagle.org/</a></p><p>分配⼀台虚拟机<br>虚拟机中安装jdk<br>解压缩kafka-eagle的压缩包<br>给kafka-eagle配置环境变量</p><p><code>export KE_HOME=/usr/local/kafka-eagle</code><br><code>export PATH=$PATH:$KE_HOME/bin</code></p><p>需要修改kafka-eagle内部的配置⽂件：<br>vim system-config.properties<br>修改⾥⾯的zk的地址和mysql的地址<br>进⼊到bin中，通过命令来启动</p><p><code>./ke.sh start</code></p><h3 id="8-2-使用"><a href="#8-2-使用" class="headerlink" title="8.2 使用"></a>8.2 使用</h3><p>kafka-eagle 监控面板</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-eagle-%E7%9B%91%E6%8E%A7%E9%9D%A2%E6%9D%BF.PNG"></p><p>kafka-监控查看节点信息</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-%E7%9B%91%E6%8E%A7%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E4%BF%A1%E6%81%AF.PNG"></p><p>kafka-eagle查看消费组与消费主题信息</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-eagle%E6%9F%A5%E7%9C%8B%E6%B6%88%E8%B4%B9%E7%BB%84%E6%B6%88%E8%B4%B9%E4%B8%BB%E9%A2%98%E4%BF%A1%E6%81%AF.PNG"></p><p>kafka-eagle查看消息积压情况</p><p><img src="https://xin997.oss-cn-beijing.aliyuncs.com/xinblogs/webimg-Linuxkafka-eagle%E6%9F%A5%E7%9C%8B%E6%B6%88%E6%81%AF%E7%A7%AF%E5%8E%8B%E6%83%85%E5%86%B5.PNG"></p>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>日志处理-Grok正则捕获</title>
    <link href="/2023/04/21/%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86-Grok%E6%AD%A3%E5%88%99%E6%8D%95%E8%8E%B7/"/>
    <url>/2023/04/21/%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86-Grok%E6%AD%A3%E5%88%99%E6%8D%95%E8%8E%B7/</url>
    
    <content type="html"><![CDATA[<p>一般系统或服务生成的日志都是一大长串。每个字段之间用空格隔开。logstash在获取日志是整个一串获取，如果把日志中每个字段代表的意思分割开来在传给elasticsearch。这样呈现出来的数据更加清晰，而且也能让kibana更方便的绘制图形。</p><p>Grok 是 Logstash 最重要的插件。它的主要作用就是将文本格式的字符串，转换成为具体的结构化的数据，配合正则表达式使用。</p><h1 id="Grok-正则捕获"><a href="#Grok-正则捕获" class="headerlink" title="Grok 正则捕获"></a>Grok 正则捕获</h1><p>Grok 支持把预定义的 grok 表达式 写入到文件中，官方提供的预定义 grok 表达式见：<a href="https://github.com/logstash/logstash/tree/v1.4.2/patterns%E3%80%82">https://github.com/logstash/logstash/tree/v1.4.2/patterns。</a></p><p><code>%&#123;syntax:semantic&#125;</code></p><p>syntax代表的是正则表达式替代字段，semantic是代表这个表达式对应的字段名，你可以自由命名。这个命名尽量能简单易懂的表达出这个字段代表的意思。</p><p>logstash安装时就带有已经写好的正则表达式。路径如下：</p><p><code>/usr/local/logstash-2.3.4/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns</code></p><p>或者直接访问logstash-plugins&#x2F;logstash-patterns-core · GitHub</p><p>上面IPORHOST，USER等都是在里面已经定义好的！当然还有其他的，基本能满足我们的需求。</p><h2 id="grok-patterns"><a href="#grok-patterns" class="headerlink" title="grok-patterns"></a>grok-patterns</h2><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "physical id  USERNAME [a-zA-Z0-9._-]+  USER %&#123;USERNAME&#125;  EMAILLOCALPART [a-zA-Z0-9!#$%&'*+\-/=?^_`&#123;|&#125;~]&#123;1,64&#125;(?:\.[a-zA-Z0-9!#$%&'*+\-/=?^_`&#123;|&#125;~]&#123;1,62&#125;)&#123;0,63&#125;  EMAILADDRESS %&#123;EMAILLOCALPART&#125;@%&#123;HOSTNAME&#125;  INT (?:[+-]?(?:[0-9]+))  BASE10NUM (?<![0-9.+-])(?>[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))  NUMBER (?:%&#123;BASE10NUM&#125;)  BASE16NUM (?<![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))  BASE16FLOAT \b(?<![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\b  <p>  POSINT \b(?:[1-9][0-9]<em>)\b<br>  NONNEGINT \b(?:[0-9]+)\b<br>  WORD \b\w+\b<br>  NOTSPACE \S+<br>  SPACE \s</em><br>  DATA .<em>?<br>  GREEDYDATA .</em><br>  QUOTEDSTRING (?&gt;(?&lt;!\)(?&gt;”(?&gt;\.|[^\“]+)+”|””|(?&gt;’(?&gt;\.|[^\‘]+)+’)|’’|(?&gt;<code>(?&gt;\\.|[^\\</code>]+)+&#96;)|&#96;&#96;))<br>  UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12}<br>  # URN, allowing use of RFC 2141 section 2.3 reserved characters<br>  URN urn:[0-9A-Za-z][0-9A-Za-z-]{0,31}:(?:%[0-9a-fA-F]{2}|[0-9A-Za-z()+,.:&#x3D;@;$_!*’&#x2F;?#-])+  <p></p><p>  # Networking<br>  MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})<br>  CISCOMAC (?:(?:[A-Fa-f0-9]{4}.){2}[A-Fa-f0-9]{4})<br>  WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})<br>  COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})<br>  IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?<br>  IPV4 (?&lt;![0-9])(?:(?:[0-1]?[0-9]{1,2}|2[0-4][0-9]|25[0-5])<a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a><a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a><a href="?:%5B0-1%5D?%5B0-9%5D%7B1,2%7D%7C2%5B0-4%5D%5B0-9%5D%7C25%5B0-5%5D">.</a>)(?![0-9])<br>  IP (?:%{IPV6}|%{IPV4})<br>  HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(.?|\b)<br>  IPORHOST (?:%{IP}|%{HOSTNAME})<br>  HOSTPORT %{IPORHOST}:%{POSINT}  </p><p>  # paths (only absolute paths are matched)<br>  PATH (?:%{UNIXPATH}|%{WINPATH})<br>  UNIXPATH (&#x2F;[[[:alnum:]]_%!$@:.,+<code>~</code>-]<em>)+<br>  TTY (?:&#x2F;dev&#x2F;(pts|tty([pq])?)(\w+)?&#x2F;?(?:[0-9]+))<br>  WINPATH (?&gt;[A-Za-z]+:|\)(?:\[^\?</em>]<em>)+<br>  URIPROTO <a href="%5BA-Za-z0-9+-.%5D+">A-Za-z</a>+<br>  URIHOST %{IPORHOST}(?::%{POSINT})?<br>  # uripath comes loosely from RFC1738, but mostly from what Firefox doesn’t turn into %XX<br>  URIPATH (?:&#x2F;[A-Za-z0-9$.+!</em>‘(){},<code>~</code>:;&#x3D;@#%&amp;<em>-]<em>)+<br>  URIQUERY [A-Za-z0-9$.+!</em>‘|(){},<code>~</code>@#%&amp;&#x2F;&#x3D;:;</em>?-[]&lt;&gt;]*<br>  # deprecated (kept due compatibility):<br>  URIPARAM ?%{URIQUERY}<br>  URIPATHPARAM %{URIPATH}(?:?%{URIQUERY})?<br>  URI %{URIPROTO}:&#x2F;&#x2F;(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATH}(?:?%{URIQUERY})?)?  </p><p>  # Months: January, Feb, 3, 03, 12, December<br>  MONTH \b(?:[Jj]an(?:uary|uar)?|[Ff]eb(?:ruary|ruar)?|<a href="?:a%7C%C3%A4">Mm</a>?r(?:ch|z)?|[Aa]pr(?:il)?|[Mm]a(?:y|i)?|[Jj]un(?:e|i)?|[Jj]ul(?:y|i)?|[Aa]ug(?:ust)?|[Ss]ep(?:tember)?|<a href="?:c%7Ck">Oo</a>?t(?:ober)?|[Nn]ov(?:ember)?|[Dd]e(?:c|z)(?:ember)?)\b<br>  MONTHNUM (?:0?[1-9]|1[0-2])<br>  MONTHNUM2 (?:0[1-9]|1[0-2])<br>  MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])  </p><p>  # Days: Monday, Tue, Thu, etc…<br>  DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)  </p><p>  # Years?<br>  YEAR (?&gt;\d\d){1,2}<br>  HOUR (?:2[0123]|[01]?[0-9])<br>  MINUTE (?:[0-5][0-9])<br>  # ‘60’ is a leap second in most time standards and thus is valid.<br>  SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)<br>  TIME (?!&lt;[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9])<br>  # datestamp is YYYY&#x2F;MM&#x2F;DD-HH:MM:SS.UUUU (or something like it)<br>  DATE_US %{MONTHNUM}[&#x2F;-]%{MONTHDAY}[&#x2F;-]%{YEAR}<br>  DATE_EU %{MONTHDAY}[.&#x2F;-]%{MONTHNUM}[.&#x2F;-]%{YEAR}<br>  ISO8601_TIMEZONE (?:Z|[+-]%{HOUR}(?::?%{MINUTE}))<br>  ISO8601_SECOND %{SECOND}<br>  TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?<br>  DATE %{DATE_US}|%{DATE_EU}<br>  DATESTAMP %{DATE}[- ]%{TIME}<br>  TZ (?:[APMCE][SD]T|UTC)<br>  DATESTAMP_RFC822 %{DAY} %{MONTH} %{MONTHDAY} %{YEAR} %{TIME} %{TZ}<br>  DATESTAMP_RFC2822 %{DAY}, %{MONTHDAY} %{MONTH} %{YEAR} %{TIME} %{ISO8601_TIMEZONE}<br>  DATESTAMP_OTHER %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{TZ} %{YEAR}<br>  DATESTAMP_EVENTLOG %{YEAR}%{MONTHNUM2}%{MONTHDAY}%{HOUR}%{MINUTE}%{SECOND}  </p><p>  # Syslog Dates: Month Day HH:MM:SS<br>  SYSLOGTIMESTAMP %{MONTH} +%{MONTHDAY} %{TIME}<br>  PROG [\x21-\x5a\x5c\x5e-\x7e]+<br>  SYSLOGPROG %{PROG:[process][name]}(?:[%{POSINT:[process][pid]:int}])?<br>  SYSLOGHOST %{IPORHOST}<br>  SYSLOGFACILITY &lt;%{NONNEGINT:[log][syslog][facility][code]:int}.%{NONNEGINT:[log][syslog][priority]:int}&gt;<br>  HTTPDATE %{MONTHDAY}&#x2F;%{MONTH}&#x2F;%{YEAR}:%{TIME} %{INT}  </p><p>  # Shortcuts<br>  QS %{QUOTEDSTRING}  </p><p>  # Log formats<br>  SYSLOGBASE %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:[host][hostname]} %{SYSLOGPROG}:  </p><p>  # Log Levels<br>  LOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo?(?:rmation)?|INFO?(?:RMATION)?|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)<br>  </p></code></pre><p></p></figure><h2 id="案例实践"><a href="#案例实践" class="headerlink" title="案例实践"></a>案例实践</h2><p><strong>例1</strong>：将下面的日志文件格式拆分为5段</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  2016-09-19T18:19:00 [8.8.8.8:prd] DEBUG this is an example log message  </code></pre></figure><ul><li>时间</li><li>IP地址</li><li>环境</li><li>等级</li><li>信息</li></ul><p>使用Grok 默认提供的正则匹配后</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;TIMESTAMP_ISO8601:timestamp&#125; \[%&#123;IPV4:ip&#125;;%&#123;WORD:environment&#125;\] %&#123;LOGLEVEL:log_level&#125; %&#123;GREEDYDATA:message&#125;    <p>  这样就会生成结构化结果：<br>  &#123;<br>    “timestamp”: “2016-09-19T18:19:00”,<br>    “ip”: “8.8.8.8”,<br>    “environment”: “prd”,<br>    “log_level”: “DEBUG”,<br>    “message”: “this is an example log message”<br>  &#125;<br>  </p></code></pre><p></p></figure><p><code>TIMESTAMP_ISO8601</code> 用来匹配时间</p><p><code>IPV4</code>匹配IPV4 IP地址</p><p><code>WORD</code>匹配环境</p><p><code>LOGLEVEL</code>匹配了日志等级</p><p><code>GREEDYDATA</code>匹配后面的所有内容</p><p><strong>例2</strong>：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] "GET /blog/geekery/xvfb-firefox.html HTTP/1.1" 200 10975 "-" "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)"  </code></pre></figure><p><strong>转换后</strong>：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;IPORHOST:clientip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "%&#123;WORD:verb&#125; %&#123;DATA:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;" %&#123;NUMBER:response:int&#125; (?:-|%&#123;NUMBER:bytes:int&#125;) %&#123;QS:referrer&#125; %&#123;QS:agent&#125;  </code></pre></figure><p><strong>例3</strong>：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  220.181.108.96 - - [13/Jun/2015:21:14:28 +0000] "GET /blog/geekery/xvfb-firefox.html HTTP/1.1" 200 10975 "-" "Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)"  </code></pre></figure><p><strong>转换后</strong>：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  %&#123;IPORHOST:clientip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "%&#123;WORD:verb&#125; %&#123;DATA:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;" %&#123;NUMBER:response:int&#125; (?:-|%&#123;NUMBER:bytes:int&#125;) %&#123;QS:referrer&#125; %&#123;QS:agent&#125;  </code></pre></figure><p><strong>例4</strong>：假设我们有三个使用“common_header：payload”格式的应用程序</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  Application 1: '8.8.8.8 process-name[666]: a b 1 2 a lot of text at the end'  <p>  Application 2: ‘8.8.8.8 process-name[667]: a 1 2 3 a lot of text near the end;4’</p><p>  Application 3: ‘8.8.8.8 process-name[421]: a completely different format | 1111’<br>  </p></code></pre><p></p></figure><p><strong>转换后</strong>：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  grok &#123;  "match" => &#123; "message => [    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;WORD:word_1&#125; %&#123;WORD:word_2&#125; %&#123;NUMBER:number_1&#125; %&#123;NUMBER:number_2&#125; %&#123;DATA:data&#125;',    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;WORD:word_1&#125; %&#123;NUMBER:number_1&#125; %&#123;NUMBER:number_2&#125; %&#123;NUMBER:number_3&#125; %&#123;DATA:data&#125;;%&#123;NUMBER:number_4&#125;',    '%&#123;IPORHOST:clientip&#125; %&#123;DATA:process_name&#125;\[%&#123;NUMBER:process_id&#125;\]: %&#123;DATA:data&#125; | %&#123;NUMBER:number&#125;'    ] &#125;&#125;  </code></pre></figure><h3 id="下面针对Apache日志来分割处理"><a href="#下面针对Apache日志来分割处理" class="headerlink" title="下面针对Apache日志来分割处理"></a>下面针对Apache日志来分割处理</h3><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  192.168.10.97 - - [19/Jul/2016:16:28:52 +0800] "GET / HTTP/1.1" 200 23 "-" "Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36"  </code></pre></figure><p>日志中每个字段之间空格隔开，分别对应message中的字段。</p><p>如：%{IPORHOST:addre} –&gt; 192.168.10.97</p><p>但问题是IPORHOST又不是正则表达式，怎么能匹配IP地址呢？</p><p>因为IPPRHOST是grok表达式，它代表的正则表达式如下：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  IPV6 ((([0-9A-Fa-f]&#123;1,4&#125;:)&#123;7&#125;([0-9A-Fa-f]&#123;1,4&#125;|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;6&#125;(:[0-9A-Fa-f]&#123;1,4&#125;|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;5&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,2&#125;)|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;)|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;4&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,3&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;3&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,4&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,2&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;2&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,5&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,3&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(([0-9A-Fa-f]&#123;1,4&#125;:)&#123;1&#125;(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,6&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,4&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:))|(:(((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;1,7&#125;)|((:[0-9A-Fa-f]&#123;1,4&#125;)&#123;0,5&#125;:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d))&#123;3&#125;))|:)))(%.+)?  IPV4 (?<![0-9])(?:(?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5])[.](?:[0-1]?[0-9]&#123;1,2&#125;|2[0-4][0-9]|25[0-5]))(?![0-9])  IP (?:%&#123;IPV6&#125;|%&#123;IPV4&#125;)  HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]&#123;0,62&#125;))*(\.?|\b)  IPORHOST (?:%&#123;IP&#125;|%&#123;HOSTNAME&#125;)  </code></code></pre></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  IPORHOST代表的是ipv4或者ipv6或者HOSTNAME所匹配的grok表达式。<p>  上面的IPORHOST有点复杂，我们来看看简单点的，如USER</p><p>  USERNAME [a-zA-Z0-9._-]+     </p><p>  #USERNAME是匹配由字母，数字，“.”, “_”, “-“组成的任意字符</p><p>  USER %&#123;USERNAME&#125;</p><p>  #USER代表USERNAME的正则表达式</p><p>  第一行，用普通的正则表达式来定义一个 grok 表达式；</p><p>  第二行，通过打印赋值格式，用前面定义好的 grok 表达式来定义另一个 grok 表达式。<br>  </p></code></pre><p></p></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  filter &#123;    if [type] == "apache" &#123;      grok &#123;        match => ["message" => "%&#123;IPORHOST:addre&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \"%&#123;WORD:http_method&#125; %&#123;NOTSPACE:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\" %&#123;NUMBER:status&#125; (?:%&#123;NUMBER:bytes&#125;|-) \"(?:%&#123;URI:http_referer&#125;|-)\" \"%&#123;GREEDYDATA:User_Agent&#125;\""]        remove_field => ["message"]      &#125;      date &#123;        match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]      &#125;    &#125;  &#125;  </code></pre></figure><h3 id="Httpd"><a href="#Httpd" class="headerlink" title="Httpd"></a>Httpd</h3><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  HTTPDUSER %&#123;EMAILADDRESS&#125;|%&#123;USER&#125;  HTTPDERROR_DATE %&#123;DAY&#125; %&#123;MONTH&#125; %&#123;MONTHDAY&#125; %&#123;TIME&#125; %&#123;YEAR&#125;  <p>  # Log formats<br>  HTTPD_COMMONLOG %&#123;IPORHOST:clientip&#125; %&#123;HTTPDUSER:ident&#125; %&#123;HTTPDUSER:auth&#125; [%&#123;HTTPDATE:timestamp&#125;] “(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP&#x2F;%&#123;NUMBER:httpversion&#125;)?|%&#123;DATA:rawrequest&#125;)” %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-)<br>  HTTPD_COMBINEDLOG %&#123;HTTPD_COMMONLOG&#125; %&#123;QS:referrer&#125; %&#123;QS:agent&#125;  </p><p>  # Error logs<br>  HTTPD20_ERRORLOG [%&#123;HTTPDERROR_DATE:timestamp&#125;] [%&#123;LOGLEVEL:loglevel&#125;] (?:[client %&#123;IPORHOST:clientip&#125;] )&#123;0,1&#125;%&#123;GREEDYDATA:message&#125;<br>  HTTPD24_ERRORLOG [%&#123;HTTPDERROR_DATE:timestamp&#125;] [%&#123;WORD:module&#125;:%&#123;LOGLEVEL:loglevel&#125;] [pid %&#123;POSINT:pid&#125;(:tid %&#123;NUMBER:tid&#125;)?]( (%&#123;POSINT:proxy_errorcode&#125;)%&#123;DATA:proxy_message&#125;:)?( [client %&#123;IPORHOST:clientip&#125;:%&#123;POSINT:clientport&#125;])?( %&#123;DATA:errorcode&#125;:)? %&#123;GREEDYDATA:message&#125;<br>  HTTPD_ERRORLOG %&#123;HTTPD20_ERRORLOG&#125;|%&#123;HTTPD24_ERRORLOG&#125;  </p><p>  # Deprecated<br>  COMMONAPACHELOG %&#123;HTTPD_COMMONLOG&#125;<br>  COMBINEDAPACHELOG %&#123;HTTPD_COMBINEDLOG&#125;<br>  </p></code></pre><p></p></figure><h3 id="java"><a href="#java" class="headerlink" title="java"></a>java</h3><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  JAVACLASS (?:[a-zA-Z$_][a-zA-Z$_0-9]*\.)*[a-zA-Z$_][a-zA-Z$_0-9]*  <p>  #Space is an allowed character to match special cases like ‘Native Method’ or ‘Unknown Source’<br>  JAVAFILE (?:[A-Za-z0-9_. -]+)  </p><p>  #Allow special <init>, <clinit> methods<br>  JAVAMETHOD (?:(&lt;(?:cl)?init&gt;)|[a-zA-Z$_][a-zA-Z$_0-9]*)  </clinit></init></p><p>  #Line number is optional in special cases ‘Native method’ or ‘Unknown source’<br>  JAVASTACKTRACEPART %&#123;SPACE&#125;at %&#123;JAVACLASS:class&#125;.%&#123;JAVAMETHOD:method&#125;(%&#123;JAVAFILE:file&#125;(?::%&#123;NUMBER:line&#125;)?)  </p><p>  # Java Logs<br>  JAVATHREAD (?:[A-Z]&#123;2&#125;-Processor[\d]+)<br>  JAVACLASS (?:[a-zA-Z0-9-]+.)+[A-Za-z0-9$]+<br>  JAVAFILE (?:[A-Za-z0-9_.-]+)<br>  JAVALOGMESSAGE (.*)  </p><p>  # MMM dd, yyyy HH:mm:ss eg: Jan 9, 2014 7:13:13 AM<br>  CATALINA_DATESTAMP %&#123;MONTH&#125; %&#123;MONTHDAY&#125;, 20%&#123;YEAR&#125; %&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;) (?:AM|PM)  </p><p>  # yyyy-MM-dd HH:mm:ss,SSS ZZZ eg: 2014-01-09 17:32:25,527 -0800<br>  TOMCAT_DATESTAMP 20%&#123;YEAR&#125;-%&#123;MONTHNUM&#125;-%&#123;MONTHDAY&#125; %&#123;HOUR&#125;:?%&#123;MINUTE&#125;(?::?%&#123;SECOND&#125;) %&#123;ISO8601_TIMEZONE&#125;<br>  CATALINALOG %&#123;CATALINA_DATESTAMP:timestamp&#125; %&#123;JAVACLASS:class&#125; %&#123;JAVALOGMESSAGE:logmessage&#125;  </p><p>  # 2014-01-09 20:03:28,269 -0800 | ERROR | com.example.service.ExampleService - something compeletely unexpected happened…<br>  TOMCATLOG %&#123;TOMCAT_DATESTAMP:timestamp&#125; | %&#123;LOGLEVEL:level&#125; | %&#123;JAVACLASS:class&#125; - %&#123;JAVALOGMESSAGE:logmessage&#125;</p><p>  </p></code></pre><p></p></figure><h3 id="Grok-Debugger"><a href="#Grok-Debugger" class="headerlink" title="Grok Debugger"></a>Grok Debugger</h3><p>当我们拿到一段日志，按照上面的grok表达式一个个去匹配时，我们如何确定我们匹配的是否正确呢？</p><p><a href="https://grokconstructor.appspot.com/do/match#result">https://grokconstructor.appspot.com/do/match#result</a> 这个地址可以满足我们的测试需求。就拿上面apache的日志测试。</p><p>点击后就出现如下数据，你写的每个grok表达式都获取到值了。为了测试准确，可以多测试几条日志。</p><p>配置文件：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  \# ---------------input 输入模块-----------------------  input &#123;  beats &#123;  port => 5044  &#125;  &#125;  <p>  # —————filter 过滤模块———————–  </p><p>  filter &#123;<br>      grok &#123;<br>          match &#x3D;&gt; &#123;<br>              “message” &#x3D;&gt; “%&#123;TIMESTAMP_ISO8601:times&#125; %&#123;HOSTNAME:hosts&#125; %&#123;USERNAME:logtype&#125;: message repeated %&#123;INT:repetition_times&#125; times: [ 日志类型:(?<Operation_type>(?&lt;&#x3D;)(.&#123;4&#125;)), (?<Operation_typ1e>(?&lt;&#x3D;)(.&#123;2&#125;)):%&#123;USER:user&#125;(%&#123;HOSTNAME:connection_method&#125;)(%&#123;HOSTNAME:connection_method&#125;), IP地址:%&#123;IPV4:connection_ip&#125;, 操作对象:%&#123;GREEDYDATA:Action_log&#125;, 操作类型:(?<behaviour_t>(?&lt;&#x3D;)(.&#123;4&#125;)), 描述:(?<Behavior_performance>(?&lt;&#x3D;)(.&#123;4&#125;))]“<br>          &#125;<br>      &#125;<br>  &#125;  </Behavior_performance></behaviour_t></Operation_typ1e></Operation_type></p><p>  # —————output 输出模块———————–  </p><p>  output &#123;<br>  elasticsearch &#123;<br>  hosts &#x3D;&gt; [“<a href="http://localhost:9200" ]">http://localhost:9200&quot;]</a><br>  index &#x3D;&gt; “sangfor-af-%&#123;+YYYY.MM.dd&#125;”<br>  #user &#x3D;&gt; “elastic”<br>  #password &#x3D;&gt; “changeme”<br>  &#125;<br>  &#125;<br>  </p></code></pre><p></p></figure><h2 id="自定义grok表达式"><a href="#自定义grok表达式" class="headerlink" title="自定义grok表达式"></a>自定义grok表达式</h2><p>grok主要有两部分：自定义正则表达式和系统预定义的模式表达式。</p><p>如果你感觉logstash自带的grok表达式不能满足需要，你也可以自己定义</p><p>如：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  filter &#123;    if [type] == "apache" &#123;      grok &#123;        patterns_dir => "/usr/local/logstash-2.3.4/ownpatterns/patterns"        match => &#123;                  "message" => "%&#123;APACHE_LOG&#125;"                  &#125;        remove_field => ["message"]      &#125;      date &#123;        match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ]      &#125;    &#125;  &#125;  <p>  #patterns_dir为自定义的grok表达式的路径。<br>  #自定义的patterns中按照logstash自带的格式书写。<br>  </p></code></pre><p></p></figure><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  APACHE_LOG %&#123;IPORHOST:addre&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \"%&#123;WORD:http_method&#125; %&#123;NOTSPACE:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\" %&#123;NUMBER:status&#125; (?:%&#123;NUMBER:bytes&#125;|-) \"(?:%&#123;URI:http_referer&#125;|-)\" \"%&#123;GREEDYDATA:User_Agent&#125;\"  <p>  #我只是把apache日志匹配的grok表达式写入自定义文件中，简化conf文件。单个字段的正则表达式匹配你可以自己书写测试。<br>  </p></code></pre><p></p></figure><p><strong>常用正则</strong></p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  (?<temMsg>(.*)(?=Report)/?) 获取Report之前的字符  (?<temMsg>(?=Report)(.*)/?) 获取Report之后的字符  (?<temMsg>(?<=report).*?(?=msg)) 截取report和msg之间的值 不包含report和msg本身 (?<temmsg>(report).*?(?=msg)) 截取包含report但不包含msg  (?<temMsg>(?<=report).*?(msg)) 截取不包含report但包含msg (?<temmsg>(report).*?(msg|request)) 输出以report开头,以msg或者以request结尾的所有包含头尾信息  (?<temMsg>(report).*?(?=(msg|request))) 输出以report开头,以msg或者以request结尾的不包含头尾信息  </temMsg></=report).*?(msg))></temMsg></=report).*?(?=msg))></temMsg></temMsg></temMsg></code></pre></figure><p><strong>grok截取字符中指定长度的内容</strong><br>要求利用grok截取日志消息中某一指定长度的内容。</p><p>Logstatsh需要两个必需参数input、output，以及一个可选参数filter。input用于输入数据的设置，output用于输出数据的设置。filter是实现数据过滤的设置。grok是在filter里面实现数据截取。</p><p>项目有一串协议消息如 7e8900000c040116432693324af0010180010005e98e0706000a7e，要求利用grok截取7e后面的四个字符，利用grok正则表达式即可实现。<br>实现代码如下：</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  filter&#123;   grok&#123; match => &#123;   "message" => "(?<mid>(?<=7e)(.&#123;4&#125;))" &#125; < code></=7e)(.&#123;4&#125;))"></mid></code></pre></figure><p>代码解释：</p><p><code>message</code>：即输入的数据信息。</p><p><code>mid</code>：即输出结果的名称</p><p><code>(?&lt;=7e)</code>：即表示获取7e后面的字符，但不包括7e</p><p><code>(.&#123;4&#125;)</code>：即表示获取的字符长度为4个</p>]]></content>
    
    
    <categories>
      
      <category>运维</category>
      
    </categories>
    
    
    <tags>
      
      <tag>日志</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AWS数据传输费用怎么算？</title>
    <link href="/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/"/>
    <url>/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h2 id="AWS的数据传输类型大致有如下三类："><a href="#AWS的数据传输类型大致有如下三类：" class="headerlink" title="AWS的数据传输类型大致有如下三类："></a><strong>AWS的数据传输类型大致有如下三类</strong>：</h2><ul><li>与Internet之间的数据传输</li><li>AWS内部跨区域的数据传输</li><li>AWS内部同一区域的数据传输<br>本文将以ap-southeast-2区域中的EC2和S3为例。</li></ul><h2 id="与Internet之间的数据传输费用计算"><a href="#与Internet之间的数据传输费用计算" class="headerlink" title="与Internet之间的数据传输费用计算"></a><strong>与Internet之间的数据传输费用计算</strong></h2><p>所有从Internet到AWS的流量是免费的，所有从AWS到Internet的流量是收费的。即对AWS服务而言，上行收费，下行免费。</p><p>针对上行流量，AWS根据不同的使用量采用不同的费率，下表中展示的是ap-southeast-2区域从AWS到Internet的数据传输费率。</p><table><thead><tr><th>Rate tiers</th><th>Pricing</th></tr></thead><tbody><tr><td>Up to 1 GB &#x2F; Month</td><td>$0.00 per GB</td></tr><tr><td>Next 9.999 TB</td><td>$0.114 per GB</td></tr><tr><td>Next 40 TB &#x2F; Month</td><td>$0.098 per GB</td></tr><tr><td>Next 100 TB &#x2F; Month</td><td>$0.094 per GB</td></tr><tr><td>Greater than 150 TB &#x2F; Month</td><td>$0.092 per GB</td></tr></tbody></table><p>那么问题来了，在这一个月中S3和EC2均产生了1GB到Internet的上行流量，AWS应该收我多少钱？$0? 不是的，会产生 $0.114 费用。</p><h2 id="为啥？"><a href="#为啥？" class="headerlink" title="为啥？"></a><strong>为啥？</strong></h2><p>AWS会根据从AWS服务传输到Internet的数据总量计算数据传输费率。具体而言，AWS会将从Amazon EC2, Amazon S3, Amazon Glacier, Amazon RDS, Amazon Redshift, Amazon SES, Amazon SimpleDB, Amazon SQS, Amazon SNS, Amazon DynamoDB, AWS Storage Gateway, 和 Amazon CloudWatch Logs到Internet的流量进行合并计算数据传输费率。</p><p>比如，我们只使用了EC2和S3服务，在本月我们已经使用了10TB，那么接下来EC2或者S3到Internet的费用到会按照$0.098&#x2F;GB收费，知道使用到下一个费率标准。</p><p>简单说，下行免费，上行收费，费率算总量。</p><h2 id="跨区域的数据传输费用计算"><a href="#跨区域的数据传输费用计算" class="headerlink" title="跨区域的数据传输费用计算"></a><strong>跨区域的数据传输费用计算</strong></h2><p>不同区域对跨区域数据传输的费率是不一样的。对于上行的数据传输会按照费率收取费用，对于下行的数据传输不收费。</p><p>比如现在有2台EC2实例A和B，A在悉尼(ap-southeast-2)，B在新加坡(ap-southeast-1)。这两台实例之间如何收取数据传输费用？</p><p>已知从悉尼ap-southeast-2到其他区域的数据传输费用为 $0.14&#x2F;GB，从新加坡ap-southeast-1到其他区域的数据传输费用为 $0.09&#x2F;GB</p><p>则从A给B传输1GB的数据，A需要付出数据传输费用 $0.14，B不需要付费。从B给A传输1GB的数据，A不需要付费，B需要付费 $0.09。</p><p>下行免费，上行收费，费率分区域。</p><h2 id="到CloudFront的数据传输费用计算"><a href="#到CloudFront的数据传输费用计算" class="headerlink" title="到CloudFront的数据传输费用计算"></a><strong>到CloudFront的数据传输费用计算</strong></h2><p>无论EC2还是S3到CloudFront的数据传输都是免费的。</p><h2 id="同一区域内的数据传输费用计算"><a href="#同一区域内的数据传输费用计算" class="headerlink" title="同一区域内的数据传输费用计算"></a><strong>同一区域内的数据传输费用计算</strong></h2><h2 id="S3"><a href="#S3" class="headerlink" title="S3"></a><strong>S3</strong></h2><p>S3 bucket之间在同一区域进行数据传输不收费。</p><p>S3和其他AWS服务在同一区域进行数据传输不收费。比如EC2和S3之间传输数据是免费的。</p><h2 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a><strong>EC2</strong></h2><ul><li><p>Amazon EC2，Amazon RDS，Amazon Redshift，Amazon DynamoDB Accelerator（DAX），Amazon ElastiCach 和 Elastic Network Interfaces进行跨可用区或使用VPC对等连接传输数据，上下行都需要收费，$0.01&#x2F;GB<br>比如在可用区A中有1台EC2 EC2-A，在可用区B中有1台EC EC2-B。当EC2-A向EC2-B传输1G数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p></li><li><p>同一个区域内，使用公网IPv4或者弹性IPv4地址传输数据，上下行都需要收费，$0.01&#x2F;GB。<br>比如在可用区A中有两台EC2 EC2-A和EC2-B，它们之间使用公网IP传输数据是需要收费的，假如EC2-A向EC2-B发送1GB的数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p></li></ul><p>Q: 跨可用区使用Public IP传输数据如何收费？<br>跨区域使用Public IP或者EIP传输数据只会收一次费用。<br>比如在可用区A中有1台EC2 EC2-A，在可用区B中有1台EC EC2-B。当EC2-A通过EIP向EC2-B传输1G数据，EC2-A需要支付 $0.01 上行数据传输费用，EC2-B需要支付 $0.01 下行数据传输费用。总共需要 $0.02 数据传输费用。</p><ul><li><p>同一个区域内，使用IPv6跨VPC传输数据，上下行都需要收费，$0.01&#x2F;GB。</p></li><li><p>同一个可用区内Amazon EC2, Amazon RDS, Amazon Redshift, Amazon ElastiCache instances 和 Elastic Network Interfaces 之间传输数据免费。如果使用VPC对等连接，则需要按照VPC对等连接的费率收费。</p></li></ul><p>比如在可用区A中有两台EC2 EC2-A和EC2-B，它们之间使用私有IP传输数据是免费的。</p><ul><li><p>在同一区域中内 Amazon S3、Amazon Glacier、Amazon DynamoDB、Amazon SES、Amazon SQS、Amazon Kinesis、Amazon ECR、Amazon SNS、Amazon SimpleDB 和 Amazon EC2 实例之间传输数据是免费的。通过PrivateLink终端节点访问的AWS服务将产生标准PrivateLink费用。</p></li><li><p>使用私有 IP 地址从 Amazon Classic Elastic Load Balancer 和 Amazon Application Elastic Load Balancer与EC2 实例之间传输数据是免费的。</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p><strong>EC2</strong><br><img src="https://github.com/JohnnySXY/JohnnySXY.github.io/blob/master/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/ec2.png?raw=true"></p><p><strong>S3</strong><br><img src="https://github.com/JohnnySXY/JohnnySXY.github.io/blob/master/2023/04/20/AWS%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E8%B4%B9%E7%94%A8%E6%80%8E%E4%B9%88%E7%AE%97%EF%BC%9F/s3.png?raw=true"></p>]]></content>
    
    
    <categories>
      
      <category>CLOUD</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AWS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于如何在hexo博客上发布和删除博文</title>
    <link href="/2023/04/20/Hexo-Release-OR-Delete-Article/"/>
    <url>/2023/04/20/Hexo-Release-OR-Delete-Article/</url>
    
    <content type="html"><![CDATA[<p><span style="color: #519D9E; ">关于如何在hexo博客上发布和删除博文</span></p><h2 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a><strong>创建文章</strong></h2><p>进入博客目录，在 &#x2F;source&#x2F;_posts 文件夹下直接建立一个.md文件</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo new “这里填入文章的标题”  </code></pre></figure><p>.md文件注意使用带有makedown语法的编辑器打开，对文章进行编辑，你可以在Hexo-&gt;Source-&gt;_post目录下看到你新创建的那个文章，还有一个配套的文件夹，里面放这边博文的图片资源</p><p>文章标题，日期，标签，分类</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  title: 文章标题  date: 2015-11-13 15:40:25  tags: 标签  categories: 分类  </code></pre></figure><p>文章插入图片需要用到一个Hexo的插件，首先cd到hexo的根目录下</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  npm install https://github.com/CodeFalling/hexo-asset-image –save  </code></pre></figure><p>然后把图片放入对应文章的配套文件夹下</p><p>如果要进行代码书写，代码样式可自行下载</p><h2 id="发布新建文章"><a href="#发布新建文章" class="headerlink" title="发布新建文章"></a><strong>发布新建文章</strong></h2><p>文章写好后，直接在git bash中执行以下命令即可直接发布文章</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo d -g  </code></pre></figure><p>如果发布的时候出现错误</p><p><code>ERROR Deployer not found: git</code></p><p>执行</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  npm install hexo-deployer-git –save  </code></pre></figure><h2 id="删除文章"><a href="#删除文章" class="headerlink" title="删除文章"></a><strong>删除文章</strong></h2><p>删除文章的过程一样也很简单，先删除本地文件，然后通过生成和部署命令进而将远程仓库中的文件也一并删除。具体来说，以最开始默认形成的helloworld.md这篇文章为例。</p><p>首先进入到source &#x2F; _post 文件夹中，找到helloworld.md文件，在本地直接执行删除。然后依次执行</p><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  hexo d -g  </code></pre></figure><p>再去主页查看你就会发现你的博客上面已经空空如也了，这就是如何删除文章的方法。</p>]]></content>
    
    
    <categories>
      
      <category>Hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>命令</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Centos查看CPU核数命令</title>
    <link href="/2023/04/20/Centos-CPU-Check-Info/"/>
    <url>/2023/04/20/Centos-CPU-Check-Info/</url>
    
    <content type="html"><![CDATA[<h1 id="总核数-x3D-物理CPU个数-X-每颗物理CPU的核数"><a href="#总核数-x3D-物理CPU个数-X-每颗物理CPU的核数" class="headerlink" title="总核数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数"></a>总核数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数</h1><h1 id="总逻辑CPU数-x3D-物理CPU个数-X-每颗物理CPU的核数-X-超线程数"><a href="#总逻辑CPU数-x3D-物理CPU个数-X-每颗物理CPU的核数-X-超线程数" class="headerlink" title="总逻辑CPU数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数 X 超线程数"></a>总逻辑CPU数 &#x3D; 物理CPU个数 X 每颗物理CPU的核数 X 超线程数</h1><h1 id="查看物理CPU个数"><a href="#查看物理CPU个数" class="headerlink" title="查看物理CPU个数"></a>查看物理CPU个数</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "physical id"| sort| uniq| wc -l  </code></pre></figure><h1 id="查看每个物理CPU中core的个数-即核数"><a href="#查看每个物理CPU中core的个数-即核数" class="headerlink" title="查看每个物理CPU中core的个数(即核数)"></a>查看每个物理CPU中core的个数(即核数)</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "cpu cores"| uniq  </code></pre></figure><h1 id="查看逻辑CPU的个数"><a href="#查看逻辑CPU的个数" class="headerlink" title="查看逻辑CPU的个数"></a>查看逻辑CPU的个数</h1><figure class="highlight">  <figcaption>This is a code block</figcaption>  <pre><code class="language-shell">  cat /proc/cpuinfo| grep "processor"| wc -l  </code></pre></figure>]]></content>
    
    
    <categories>
      
      <category>SYSTEM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CENTOS</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
